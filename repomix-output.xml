This file is a merged representation of a subset of the codebase, containing files not matching ignore patterns, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of a subset of the repository's contents that is considered the most important context.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching these patterns are excluded: .gitignore, **/favicons/, ./tests, docs/public, docs/.vitepress/cache, docs/.vitepress/dist, /node_modules/, /.git/, **/*.png, /.ttf, **/.woff2, dist/, build/, /package-lock.json, /yarn.lock, .github/
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
chatbot/
  chatbot.html
  marked.umd.js
docs/
  .vitepress/
    config.mjs
  api-examples.md
  configuration.md
  deployment.md
  index.md
  providers.md
  quickstart.md
  sdk-usage.md
  testing.md
.env.example
AGENTS.md
eslint.config.cjs
main.js
openai-server.js
package.json
provider.js
readme.md
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="eslint.config.cjs">
module.exports = [
	{
		languageOptions: {
			parserOptions: {
				ecmaVersion: 13,
				impliedStrict: true,
			}
		},
		rules: {
			"no-trailing-spaces": "error",
			"linebreak-style": ["error", "unix"],
			"quotes": ["error", "double"],
			"one-var": ["error", "never"],
			"brace-style": ["error", "allman", { allowSingleLine: true }],
			"space-before-blocks": "warn",
			"func-call-spacing": "error",
			"space-before-function-paren": "error",
			"space-in-parens": ["error", "always", { exceptions: ["{}"] }],
			"keyword-spacing": "error",
			"comma-spacing": "error",
			"space-unary-ops": "error",
			"block-spacing": "error",
			"arrow-spacing": "error",
			"key-spacing": "error",
			"comma-style": "error",
			"space-infix-ops": "error",
			"array-bracket-spacing": "error",
			"object-curly-spacing": ["error", "always"],
			"no-multi-spaces": "error",
			"operator-linebreak": "error",
			"function-paren-newline": "warn",
			"arrow-body-style": ["error", "always"],
			"no-template-curly-in-string": "error",
			"no-new-object": "error",
			"no-extra-parens": ["error", "all", { conditionalAssign: false }],
			"no-empty-function": "error",
			"no-empty": ["warn", { allowEmptyCatch: true }],
			"no-eq-null": "error",
			"no-extra-bind": "error",
			"no-self-compare": "error",
			"no-useless-call": "error",
			"no-undefined": "error",
			"no-array-constructor": "error",
			"prefer-destructuring": ["error",
				{
					VariableDeclarator: { array: false, object: true }, AssignmentExpression: { array: false, object: false } }, { enforceForRenamedProperties: false
				}
			],
			"object-shorthand": "warn",
			"prefer-spread": "warn",
			"prefer-template": "warn",
			"no-loop-func": "warn",
			"prefer-rest-params": "warn",
			"no-new-func": "warn",
			"no-unneeded-ternary": "warn",
			"no-process-exit": "off",
			"require-await": "warn",
			"indent": ["error", "tab", { MemberExpression: 0 }],
			"no-tabs": 0,
		},
	},
];
</file>

<file path="chatbot/marked.umd.js">
/**
 * marked v17.0.1 - a markdown parser
 * Copyright (c) 2018-2025, MarkedJS. (MIT License)
 * Copyright (c) 2011-2018, Christopher Jeffrey. (MIT License)
 * https://github.com/markedjs/marked
 */

/**
 * DO NOT EDIT THIS FILE
 * The code in this file is generated from files in ./src/
 */
( function ( g, f )
{
	if ( typeof exports == "object" && typeof module < "u" ) { module.exports = f() }
	else if ( "function" == typeof define && define.amd ) { define( "marked", f ) }
	else { g["marked"] = f() }
}( typeof globalThis < "u" ? globalThis : typeof self < "u" ? self : this, function ()
{
	var exports = {};var __exports = exports;var module = { exports };
	"use strict";var Z = Object.defineProperty;var xe = Object.getOwnPropertyDescriptor;var be = Object.getOwnPropertyNames;var Re = Object.prototype.hasOwnProperty;var Te = ( l, e ) => { for ( var t in e )Z( l, t, { get: e[t], enumerable: !0 }) }; var Oe = ( l, e, t, n ) => { if ( e && typeof e == "object" || typeof e == "function" ) for ( let r of be( e ) )!Re.call( l, r ) && r !== t && Z( l, r, { get: () => { return e[r] }, enumerable: !( n = xe( e, r ) ) || n.enumerable });return l };var we = l => { return Oe( Z({}, "__esModule", { value: !0 }), l ) };var kt = {};Te( kt, { Hooks: () => { return S }, Lexer: () => { return x }, Marked: () => { return A }, Parser: () => { return b }, Renderer: () => { return P }, TextRenderer: () => { return $ }, Tokenizer: () => { return y }, defaults: () => { return T }, getDefaults: () => { return _ }, lexer: () => { return ht }, marked: () => { return d }, options: () => { return it }, parse: () => { return pt }, parseInline: () => { return ut }, parser: () => { return ct }, setOptions: () => { return ot }, use: () => { return at }, walkTokens: () => { return lt } });module.exports = we( kt );function _ () { return { async: !1, breaks: !1, extensions: null, gfm: !0, hooks: null, pedantic: !1, renderer: null, silent: !1, tokenizer: null, walkTokens: null } } var T = _();function G ( l ) { T = l } var I = { exec: () => { return null } };function k ( l, e = "" ) { let t = typeof l == "string" ? l : l.source; let n = { replace: ( r, i ) => { let s = typeof i == "string" ? i : i.source;return s = s.replace( m.caret, "$1" ), t = t.replace( r, s ), n }, getRegex: () => { return new RegExp( t, e ) } };return n } var ye = ( () =>
	{
		try { return !!new RegExp( "(?<=1)(?<!1)" ) }
		catch { return !1 }
	})(); var m = { codeRemoveIndent: /^(?: {1,4}| {0,3}\t)/gm, outputLinkReplace: /\\([\[\]])/g, indentCodeCompensation: /^(\s+)(?:```)/, beginningSpace: /^\s+/, endingHash: /#$/, startingSpaceChar: /^ /, endingSpaceChar: / $/, nonSpaceChar: /[^ ]/, newLineCharGlobal: /\n/g, tabCharGlobal: /\t/g, multipleSpaceGlobal: /\s+/g, blankLine: /^[ \t]*$/, doubleBlankLine: /\n[ \t]*\n[ \t]*$/, blockquoteStart: /^ {0,3}>/, blockquoteSetextReplace: /\n {0,3}((?:=+|-+) *)(?=\n|$)/g, blockquoteSetextReplace2: /^ {0,3}>[ \t]?/gm, listReplaceTabs: /^\t+/, listReplaceNesting: /^ {1,4}(?=( {4})*[^ ])/g, listIsTask: /^\[[ xX]\] +\S/, listReplaceTask: /^\[[ xX]\] +/, listTaskCheckbox: /\[[ xX]\]/, anyLine: /\n.*\n/, hrefBrackets: /^<(.*)>$/, tableDelimiter: /[:|]/, tableAlignChars: /^\||\| *$/g, tableRowBlankLine: /\n[ \t]*$/, tableAlignRight: /^ *-+: *$/, tableAlignCenter: /^ *:-+: *$/, tableAlignLeft: /^ *:-+ *$/, startATag: /^<a /i, endATag: /^<\/a>/i, startPreScriptTag: /^<(pre|code|kbd|script)(\s|>)/i, endPreScriptTag: /^<\/(pre|code|kbd|script)(\s|>)/i, startAngleBracket: /^</, endAngleBracket: />$/, pedanticHrefTitle: /^([^'"]*[^\s])\s+(['"])(.*)\2/, unicodeAlphaNumeric: /[\p{L}\p{N}]/u, escapeTest: /[&<>"']/, escapeReplace: /[&<>"']/g, escapeTestNoEncode: /[<>"']|&(?!(#\d{1,7}|#[Xx][a-fA-F0-9]{1,6}|\w+);)/, escapeReplaceNoEncode: /[<>"']|&(?!(#\d{1,7}|#[Xx][a-fA-F0-9]{1,6}|\w+);)/g, unescapeTest: /&(#(?:\d+)|(?:#x[0-9A-Fa-f]+)|(?:\w+));?/ig, caret: /(^|[^\[])\^/g, percentDecode: /%25/g, findPipe: /\|/g, splitPipe: / \|/, slashPipe: /\\\|/g, carriageReturn: /\r\n|\r/g, spaceLine: /^ +$/gm, notSpaceStart: /^\S*/, endingNewline: /\n$/, listItemRegex: l => { return new RegExp( `^( {0,3}${l})((?:[	 ][^\\n]*)?(?:\\n|$))` ) }, nextBulletRegex: l => { return new RegExp( `^ {0,${Math.min( 3, l - 1 )}}(?:[*+-]|\\d{1,9}[.)])((?:[ 	][^\\n]*)?(?:\\n|$))` ) }, hrRegex: l => { return new RegExp( `^ {0,${Math.min( 3, l - 1 )}}((?:- *){3,}|(?:_ *){3,}|(?:\\* *){3,})(?:\\n+|$)` ) }, fencesBeginRegex: l => { return new RegExp( `^ {0,${Math.min( 3, l - 1 )}}(?:\`\`\`|~~~)` ) }, headingBeginRegex: l => { return new RegExp( `^ {0,${Math.min( 3, l - 1 )}}#` ) }, htmlBeginRegex: l => { return new RegExp( `^ {0,${Math.min( 3, l - 1 )}}<(?:[a-z].*>|!--)`, "i" ) } }; var Pe = /^(?:[ \t]*(?:\n|$))+/; var Se = /^((?: {4}| {0,3}\t)[^\n]+(?:\n(?:[ \t]*(?:\n|$))*)?)+/; var $e = /^ {0,3}(`{3,}(?=[^`\n]*(?:\n|$))|~{3,})([^\n]*)(?:\n|$)(?:|([\s\S]*?)(?:\n|$))(?: {0,3}\1[~`]* *(?=\n|$)|$)/; var E = /^ {0,3}((?:-[\t ]*){3,}|(?:_[ \t]*){3,}|(?:\*[ \t]*){3,})(?:\n+|$)/; var _e = /^ {0,3}(#{1,6})(?=\s|$)(.*)(?:\n+|$)/; var Q = /(?:[*+-]|\d{1,9}[.)])/; var se = /^(?!bull |blockCode|fences|blockquote|heading|html|table)((?:.|\n(?!\s*?\n|bull |blockCode|fences|blockquote|heading|html|table))+?)\n {0,3}(=+|-+) *(?:\n+|$)/; var ie = k( se ).replace( /bull/g, Q ).replace( /blockCode/g, /(?: {4}| {0,3}\t)/ ).replace( /fences/g, / {0,3}(?:`{3,}|~{3,})/ ).replace( /blockquote/g, / {0,3}>/ ).replace( /heading/g, / {0,3}#{1,6}/ ).replace( /html/g, / {0,3}<[^\n>]+>\n/ ).replace( /\|table/g, "" ).getRegex(); var Le = k( se ).replace( /bull/g, Q ).replace( /blockCode/g, /(?: {4}| {0,3}\t)/ ).replace( /fences/g, / {0,3}(?:`{3,}|~{3,})/ ).replace( /blockquote/g, / {0,3}>/ ).replace( /heading/g, / {0,3}#{1,6}/ ).replace( /html/g, / {0,3}<[^\n>]+>\n/ ).replace( /table/g, / {0,3}\|?(?:[:\- ]*\|)+[\:\- ]*\n/ ).getRegex(); var F = /^([^\n]+(?:\n(?!hr|heading|lheading|blockquote|fences|list|html|table| +\n)[^\n]+)*)/; var Me = /^[^\n]+/; var j = /(?!\s*\])(?:\\[\s\S]|[^\[\]\\])+/; var ze = k( /^ {0,3}\[(label)\]: *(?:\n[ \t]*)?([^<\s][^\s]*|<.*?>)(?:(?: +(?:\n[ \t]*)?| *\n[ \t]*)(title))? *(?:\n+|$)/ ).replace( "label", j ).replace( "title", /(?:"(?:\\"?|[^"\\])*"|'[^'\n]*(?:\n[^'\n]+)*\n?'|\([^()]*\))/ ).getRegex(); var Ae = k( /^( {0,3}bull)([ \t][^\n]+?)?(?:\n|$)/ ).replace( /bull/g, Q ).getRegex(); var v = "address|article|aside|base|basefont|blockquote|body|caption|center|col|colgroup|dd|details|dialog|dir|div|dl|dt|fieldset|figcaption|figure|footer|form|frame|frameset|h[1-6]|head|header|hr|html|iframe|legend|li|link|main|menu|menuitem|meta|nav|noframes|ol|optgroup|option|p|param|search|section|summary|table|tbody|td|tfoot|th|thead|title|tr|track|ul"; var U = /<!--(?:-?>|[\s\S]*?(?:-->|$))/; var Ce = k( "^ {0,3}(?:<(script|pre|style|textarea)[\\s>][\\s\\S]*?(?:</\\1>[^\\n]*\\n+|$)|comment[^\\n]*(\\n+|$)|<\\?[\\s\\S]*?(?:\\?>\\n*|$)|<![A-Z][\\s\\S]*?(?:>\\n*|$)|<!\\[CDATA\\[[\\s\\S]*?(?:\\]\\]>\\n*|$)|</?(tag)(?: +|\\n|/?>)[\\s\\S]*?(?:(?:\\n[ 	]*)+\\n|$)|<(?!script|pre|style|textarea)([a-z][\\w-]*)(?:attribute)*? */?>(?=[ \\t]*(?:\\n|$))[\\s\\S]*?(?:(?:\\n[ 	]*)+\\n|$)|</(?!script|pre|style|textarea)[a-z][\\w-]*\\s*>(?=[ \\t]*(?:\\n|$))[\\s\\S]*?(?:(?:\\n[ 	]*)+\\n|$))", "i" ).replace( "comment", U ).replace( "tag", v ).replace( "attribute", / +[a-zA-Z:_][\w.:-]*(?: *= *"[^"\n]*"| *= *'[^'\n]*'| *= *[^\s"'=<>`]+)?/ ).getRegex(); var oe = k( F ).replace( "hr", E ).replace( "heading", " {0,3}#{1,6}(?:\\s|$)" ).replace( "|lheading", "" ).replace( "|table", "" ).replace( "blockquote", " {0,3}>" ).replace( "fences", " {0,3}(?:`{3,}(?=[^`\\n]*\\n)|~{3,})[^\\n]*\\n" ).replace( "list", " {0,3}(?:[*+-]|1[.)]) " ).replace( "html", "</?(?:tag)(?: +|\\n|/?>)|<(?:script|pre|style|textarea|!--)" ).replace( "tag", v ).getRegex(); var Ie = k( /^( {0,3}> ?(paragraph|[^\n]*)(?:\n|$))+/ ).replace( "paragraph", oe ).getRegex(); var K = { blockquote: Ie, code: Se, def: ze, fences: $e, heading: _e, hr: E, html: Ce, lheading: ie, list: Ae, newline: Pe, paragraph: oe, table: I, text: Me }; var ne = k( "^ *([^\\n ].*)\\n {0,3}((?:\\| *)?:?-+:? *(?:\\| *:?-+:? *)*(?:\\| *)?)(?:\\n((?:(?! *\\n|hr|heading|blockquote|code|fences|list|html).*(?:\\n|$))*)\\n*|$)" ).replace( "hr", E ).replace( "heading", " {0,3}#{1,6}(?:\\s|$)" ).replace( "blockquote", " {0,3}>" ).replace( "code", "(?: {4}| {0,3}	)[^\\n]" ).replace( "fences", " {0,3}(?:`{3,}(?=[^`\\n]*\\n)|~{3,})[^\\n]*\\n" ).replace( "list", " {0,3}(?:[*+-]|1[.)]) " ).replace( "html", "</?(?:tag)(?: +|\\n|/?>)|<(?:script|pre|style|textarea|!--)" ).replace( "tag", v ).getRegex(); var Ee = { ...K, lheading: Le, table: ne, paragraph: k( F ).replace( "hr", E ).replace( "heading", " {0,3}#{1,6}(?:\\s|$)" ).replace( "|lheading", "" ).replace( "table", ne ).replace( "blockquote", " {0,3}>" ).replace( "fences", " {0,3}(?:`{3,}(?=[^`\\n]*\\n)|~{3,})[^\\n]*\\n" ).replace( "list", " {0,3}(?:[*+-]|1[.)]) " ).replace( "html", "</?(?:tag)(?: +|\\n|/?>)|<(?:script|pre|style|textarea|!--)" ).replace( "tag", v ).getRegex() }; var Be = { ...K, html: k( "^ *(?:comment *(?:\\n|\\s*$)|<(tag)[\\s\\S]+?</\\1> *(?:\\n{2,}|\\s*$)|<tag(?:\"[^\"]*\"|'[^']*'|\\s[^'\"/>\\s]*)*?/?> *(?:\\n{2,}|\\s*$))" ).replace( "comment", U ).replace( /tag/g, "(?!(?:a|em|strong|small|s|cite|q|dfn|abbr|data|time|code|var|samp|kbd|sub|sup|i|b|u|mark|ruby|rt|rp|bdi|bdo|span|br|wbr|ins|del|img)\\b)\\w+(?!:|[^\\w\\s@]*@)\\b" ).getRegex(), def: /^ *\[([^\]]+)\]: *<?([^\s>]+)>?(?: +(["(][^\n]+[")]))? *(?:\n+|$)/, heading: /^(#{1,6})(.*)(?:\n+|$)/, fences: I, lheading: /^(.+?)\n {0,3}(=+|-+) *(?:\n+|$)/, paragraph: k( F ).replace( "hr", E ).replace( "heading", ` *#{1,6} *[^
]` ).replace( "lheading", ie ).replace( "|table", "" ).replace( "blockquote", " {0,3}>" ).replace( "|fences", "" ).replace( "|list", "" ).replace( "|html", "" ).replace( "|tag", "" ).getRegex() }; var qe = /^\\([!"#$%&'()*+,\-./:;<=>?@\[\]\\^_`{|}~])/; var ve = /^(`+)([^`]|[^`][\s\S]*?[^`])\1(?!`)/; var ae = /^( {2,}|\\)\n(?!\s*$)/; var De = /^(`+|[^`])(?:(?= {2,}\n)|[\s\S]*?(?:(?=[\\<!\[`*_]|\b_|$)|[^ ](?= {2,}\n)))/; var D = /[\p{P}\p{S}]/u; var W = /[\s\p{P}\p{S}]/u; var le = /[^\s\p{P}\p{S}]/u; var He = k( /^((?![*_])punctSpace)/, "u" ).replace( /punctSpace/g, W ).getRegex(); var ue = /(?!~)[\p{P}\p{S}]/u; var Ze = /(?!~)[\s\p{P}\p{S}]/u; var Ge = /(?:[^\s\p{P}\p{S}]|~)/u; var Ne = k( /link|precode-code|html/, "g" ).replace( "link", /\[(?:[^\[\]`]|(?<a>`+)[^`]+\k<a>(?!`))*?\]\((?:\\[\s\S]|[^\\\(\)]|\((?:\\[\s\S]|[^\\\(\)])*\))*\)/ ).replace( "precode-", ye ? "(?<!`)()" : "(^^|[^`])" ).replace( "code", /(?<b>`+)[^`]+\k<b>(?!`)/ ).replace( "html", /<(?! )[^<>]*?>/ ).getRegex(); var pe = /^(?:\*+(?:((?!\*)punct)|[^\s*]))|^_+(?:((?!_)punct)|([^\s_]))/; var Qe = k( pe, "u" ).replace( /punct/g, D ).getRegex(); var Fe = k( pe, "u" ).replace( /punct/g, ue ).getRegex(); var ce = "^[^_*]*?__[^_*]*?\\*[^_*]*?(?=__)|[^*]+(?=[^*])|(?!\\*)punct(\\*+)(?=[\\s]|$)|notPunctSpace(\\*+)(?!\\*)(?=punctSpace|$)|(?!\\*)punctSpace(\\*+)(?=notPunctSpace)|[\\s](\\*+)(?!\\*)(?=punct)|(?!\\*)punct(\\*+)(?!\\*)(?=punct)|notPunctSpace(\\*+)(?=notPunctSpace)"; var je = k( ce, "gu" ).replace( /notPunctSpace/g, le ).replace( /punctSpace/g, W ).replace( /punct/g, D ).getRegex(); var Ue = k( ce, "gu" ).replace( /notPunctSpace/g, Ge ).replace( /punctSpace/g, Ze ).replace( /punct/g, ue ).getRegex(); var Ke = k( "^[^_*]*?\\*\\*[^_*]*?_[^_*]*?(?=\\*\\*)|[^_]+(?=[^_])|(?!_)punct(_+)(?=[\\s]|$)|notPunctSpace(_+)(?!_)(?=punctSpace|$)|(?!_)punctSpace(_+)(?=notPunctSpace)|[\\s](_+)(?!_)(?=punct)|(?!_)punct(_+)(?!_)(?=punct)", "gu" ).replace( /notPunctSpace/g, le ).replace( /punctSpace/g, W ).replace( /punct/g, D ).getRegex(); var We = k( /\\(punct)/, "gu" ).replace( /punct/g, D ).getRegex(); var Xe = k( /^<(scheme:[^\s\x00-\x1f<>]*|email)>/ ).replace( "scheme", /[a-zA-Z][a-zA-Z0-9+.-]{1,31}/ ).replace( "email", /[a-zA-Z0-9.!#$%&'*+/=?^_`{|}~-]+(@)[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\.[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)+(?![-_])/ ).getRegex(); var Je = k( U ).replace( "(?:-->|$)", "-->" ).getRegex(); var Ve = k( "^comment|^</[a-zA-Z][\\w:-]*\\s*>|^<[a-zA-Z][\\w-]*(?:attribute)*?\\s*/?>|^<\\?[\\s\\S]*?\\?>|^<![a-zA-Z]+\\s[\\s\\S]*?>|^<!\\[CDATA\\[[\\s\\S]*?\\]\\]>" ).replace( "comment", Je ).replace( "attribute", /\s+[a-zA-Z:_][\w.:-]*(?:\s*=\s*"[^"]*"|\s*=\s*'[^']*'|\s*=\s*[^\s"'=<>`]+)?/ ).getRegex(); var q = /(?:\[(?:\\[\s\S]|[^\[\]\\])*\]|\\[\s\S]|`+[^`]*?`+(?!`)|[^\[\]\\`])*?/; var Ye = k( /^!?\[(label)\]\(\s*(href)(?:(?:[ \t]*(?:\n[ \t]*)?)(title))?\s*\)/ ).replace( "label", q ).replace( "href", /<(?:\\.|[^\n<>\\])+>|[^ \t\n\x00-\x1f]*/ ).replace( "title", /"(?:\\"?|[^"\\])*"|'(?:\\'?|[^'\\])*'|\((?:\\\)?|[^)\\])*\)/ ).getRegex(); var he = k( /^!?\[(label)\]\[(ref)\]/ ).replace( "label", q ).replace( "ref", j ).getRegex(); var ke = k( /^!?\[(ref)\](?:\[\])?/ ).replace( "ref", j ).getRegex(); var et = k( "reflink|nolink(?!\\()", "g" ).replace( "reflink", he ).replace( "nolink", ke ).getRegex(); var re = /[hH][tT][tT][pP][sS]?|[fF][tT][pP]/; var X = { _backpedal: I, anyPunctuation: We, autolink: Xe, blockSkip: Ne, br: ae, code: ve, del: I, emStrongLDelim: Qe, emStrongRDelimAst: je, emStrongRDelimUnd: Ke, escape: qe, link: Ye, nolink: ke, punctuation: He, reflink: he, reflinkSearch: et, tag: Ve, text: De, url: I }; var tt = { ...X, link: k( /^!?\[(label)\]\((.*?)\)/ ).replace( "label", q ).getRegex(), reflink: k( /^!?\[(label)\]\s*\[([^\]]*)\]/ ).replace( "label", q ).getRegex() }; var N = { ...X, emStrongRDelimAst: Ue, emStrongLDelim: Fe, url: k( /^((?:protocol):\/\/|www\.)(?:[a-zA-Z0-9\-]+\.?)+[^\s<]*|^email/ ).replace( "protocol", re ).replace( "email", /[A-Za-z0-9._+-]+(@)[a-zA-Z0-9-_]+(?:\.[a-zA-Z0-9-_]*[a-zA-Z0-9])+(?![-_])/ ).getRegex(), _backpedal: /(?:[^?!.,:;*_'"~()&]+|\([^)]*\)|&(?![a-zA-Z0-9]+;$)|[?!.,:;*_'"~)]+(?!$))+/, del: /^(~~?)(?=[^\s~])((?:\\[\s\S]|[^\\])*?(?:\\[\s\S]|[^\s~\\]))\1(?=[^~]|$)/, text: k( /^([`~]+|[^`~])(?:(?= {2,}\n)|(?=[a-zA-Z0-9.!#$%&'*+\/=?_`{\|}~-]+@)|[\s\S]*?(?:(?=[\\<!\[`*~_]|\b_|protocol:\/\/|www\.|$)|[^ ](?= {2,}\n)|[^a-zA-Z0-9.!#$%&'*+\/=?_`{\|}~-](?=[a-zA-Z0-9.!#$%&'*+\/=?_`{\|}~-]+@)))/ ).replace( "protocol", re ).getRegex() }; var nt = { ...N, br: k( ae ).replace( "{2,}", "*" ).getRegex(), text: k( N.text ).replace( "\\b_", "\\b_| {2,}\\n" ).replace( /\{2,\}/g, "*" ).getRegex() }; var B = { normal: K, gfm: Ee, pedantic: Be }; var M = { normal: X, gfm: N, breaks: nt, pedantic: tt };var rt = { "&": "&amp;", "<": "&lt;", ">": "&gt;", "\"": "&quot;", "'": "&#39;" }; var de = l => { return rt[l] };function w ( l, e )
	{
		if ( e ) { if ( m.escapeTest.test( l ) ) return l.replace( m.escapeReplace, de ) }
		else if ( m.escapeTestNoEncode.test( l ) ) return l.replace( m.escapeReplaceNoEncode, de );return l
	} function J ( l )
	{
		try { l = encodeURI( l ).replace( m.percentDecode, "%" ) }
		catch { return null } return l
	} function V ( l, e ) { let t = l.replace( m.findPipe, ( i, s, a ) => { let o = !1; let u = s;for ( ;--u >= 0 && a[u] === "\\"; )o = !o;return o ? "|" : " |" }); let n = t.split( m.splitPipe ); let r = 0;if ( n[0].trim() || n.shift(), n.length > 0 && !n.at( -1 )?.trim() && n.pop(), e ) if ( n.length > e )n.splice( e );else for ( ;n.length < e; )n.push( "" );for ( ;r < n.length;r++ )n[r] = n[r].trim().replace( m.slashPipe, "|" );return n } function z ( l, e, t ) { let n = l.length;if ( n === 0 ) return "";let r = 0;for ( ;r < n; ) { let i = l.charAt( n - r - 1 );if ( i === e && !t )r++;else if ( i !== e && t )r++;else break } return l.slice( 0, n - r ) } function ge ( l, e ) { if ( l.indexOf( e[1] ) === -1 ) return -1;let t = 0;for ( let n = 0;n < l.length;n++ ) if ( l[n] === "\\" )n++;else if ( l[n] === e[0] )t++;else if ( l[n] === e[1] && ( t--, t < 0 ) ) return n;return t > 0 ? -2 : -1 } function fe ( l, e, t, n, r ) { let i = e.href; let s = e.title || null; let a = l[1].replace( r.other.outputLinkReplace, "$1" );n.state.inLink = !0;let o = { type: l[0].charAt( 0 ) === "!" ? "image" : "link", raw: t, href: i, title: s, text: a, tokens: n.inlineTokens( a ) };return n.state.inLink = !1, o } function st ( l, e, t )
	{
		let n = l.match( t.other.indentCodeCompensation );if ( n === null ) return e;let r = n[1];return e.split( `
` ).map( i => { let s = i.match( t.other.beginningSpace );if ( s === null ) return i;let [a] = s;return a.length >= r.length ? i.slice( r.length ) : i }).join( `
` )
	} var y = class
	{
		options;rules;lexer;constructor ( e ) { this.options = e || T }space ( e ) { let t = this.rules.block.newline.exec( e );if ( t && t[0].length > 0 ) return { type: "space", raw: t[0] } }code ( e )
		{
			let t = this.rules.block.code.exec( e );if ( t )
			{
				let n = t[0].replace( this.rules.other.codeRemoveIndent, "" );return { type: "code", raw: t[0], codeBlockStyle: "indented", text: this.options.pedantic ? n : z( n, `
` ) }
			}
		}fences ( e ) { let t = this.rules.block.fences.exec( e );if ( t ) { let n = t[0]; let r = st( n, t[3] || "", this.rules );return { type: "code", raw: n, lang: t[2] ? t[2].trim().replace( this.rules.inline.anyPunctuation, "$1" ) : t[2], text: r } } }heading ( e ) { let t = this.rules.block.heading.exec( e );if ( t ) { let n = t[2].trim();if ( this.rules.other.endingHash.test( n ) ) { let r = z( n, "#" );( this.options.pedantic || !r || this.rules.other.endingSpaceChar.test( r ) ) && ( n = r.trim() ) } return { type: "heading", raw: t[0], depth: t[1].length, text: n, tokens: this.lexer.inline( n ) } } }hr ( e )
		{
			let t = this.rules.block.hr.exec( e );if ( t ) return { type: "hr", raw: z( t[0], `
` ) }
		}blockquote ( e )
		{
			let t = this.rules.block.blockquote.exec( e );if ( t )
			{
				let n = z( t[0], `
` ).split( `
` ); let r = ""; let i = ""; let s = [];for ( ;n.length > 0; )
				{
					let a = !1; let o = []; let u;for ( u = 0;u < n.length;u++ ) if ( this.rules.other.blockquoteStart.test( n[u] ) )o.push( n[u] ), a = !0;else if ( !a )o.push( n[u] );else break;n = n.slice( u );let p = o.join( `
` ); let c = p.replace( this.rules.other.blockquoteSetextReplace, `
    $1` ).replace( this.rules.other.blockquoteSetextReplace2, "" );r = r ? `${r}
${p}` : p, i = i ? `${i}
${c}` : c;let g = this.lexer.state.top;if ( this.lexer.state.top = !0, this.lexer.blockTokens( c, s, !0 ), this.lexer.state.top = g, n.length === 0 ) break;let h = s.at( -1 );if ( h?.type === "code" ) break;if ( h?.type === "blockquote" )
					{
						let R = h; let f = `${R.raw }
${ n.join( `
` )}`; let O = this.blockquote( f );s[s.length - 1] = O, r = r.substring( 0, r.length - R.raw.length ) + O.raw, i = i.substring( 0, i.length - R.text.length ) + O.text;break
					}
					else if ( h?.type === "list" )
					{
						let R = h; let f = `${R.raw }
${ n.join( `
` )}`; let O = this.list( f );s[s.length - 1] = O, r = r.substring( 0, r.length - h.raw.length ) + O.raw, i = i.substring( 0, i.length - R.raw.length ) + O.raw, n = f.substring( s.at( -1 ).raw.length ).split( `
` );continue
					}
				} return { type: "blockquote", raw: r, tokens: s, text: i }
			}
		}list ( e )
		{
			let t = this.rules.block.list.exec( e );if ( t )
			{
				let n = t[1].trim(); let r = n.length > 1; let i = { type: "list", raw: "", ordered: r, start: r ? +n.slice( 0, -1 ) : "", loose: !1, items: [] };n = r ? `\\d{1,9}\\${n.slice( -1 )}` : `\\${n}`, this.options.pedantic && ( n = r ? n : "[*+-]" );let s = this.rules.other.listItemRegex( n ); let a = !1;for ( ;e; )
				{
					let u = !1; let p = ""; let c = "";if ( !( t = s.exec( e ) ) || this.rules.block.hr.test( e ) ) break;p = t[0], e = e.substring( p.length );let g = t[2].split( `
`, 1 )[0].replace( this.rules.other.listReplaceTabs, O => { return " ".repeat( 3 * O.length ) }); let h = e.split( `
`, 1 )[0]; let R = !g.trim(); let f = 0;if ( this.options.pedantic ? ( f = 2, c = g.trimStart() ) : R ? f = t[1].length + 1 : ( f = t[2].search( this.rules.other.nonSpaceChar ), f = f > 4 ? 1 : f, c = g.slice( f ), f += t[1].length ), R && this.rules.other.blankLine.test( h ) && ( p += `${h }
`, e = e.substring( h.length + 1 ), u = !0 ), !u )
					{
						let O = this.rules.other.nextBulletRegex( f ); let Y = this.rules.other.hrRegex( f ); let ee = this.rules.other.fencesBeginRegex( f ); let te = this.rules.other.headingBeginRegex( f ); let me = this.rules.other.htmlBeginRegex( f );for ( ;e; )
						{
							let H = e.split( `
`, 1 )[0]; let C;if ( h = H, this.options.pedantic ? ( h = h.replace( this.rules.other.listReplaceNesting, "  " ), C = h ) : C = h.replace( this.rules.other.tabCharGlobal, "    " ), ee.test( h ) || te.test( h ) || me.test( h ) || O.test( h ) || Y.test( h ) ) break;if ( C.search( this.rules.other.nonSpaceChar ) >= f || !h.trim() )c += `
${ C.slice( f )}`;else
							{
								if ( R || g.replace( this.rules.other.tabCharGlobal, "    " ).search( this.rules.other.nonSpaceChar ) >= 4 || ee.test( g ) || te.test( g ) || Y.test( g ) ) break;c += `
${ h}`
							}!R && !h.trim() && ( R = !0 ), p += `${H }
`, e = e.substring( H.length + 1 ), g = C.slice( f )
						}
					}i.loose || ( a ? i.loose = !0 : this.rules.other.doubleBlankLine.test( p ) && ( a = !0 ) ), i.items.push({ type: "list_item", raw: p, task: !!this.options.gfm && this.rules.other.listIsTask.test( c ), loose: !1, text: c, tokens: [] }), i.raw += p
				} let o = i.items.at( -1 );if ( o )o.raw = o.raw.trimEnd(), o.text = o.text.trimEnd();else return;i.raw = i.raw.trimEnd();for ( let u of i.items ) { if ( this.lexer.state.top = !1, u.tokens = this.lexer.blockTokens( u.text, [] ), u.task ) { if ( u.text = u.text.replace( this.rules.other.listReplaceTask, "" ), u.tokens[0]?.type === "text" || u.tokens[0]?.type === "paragraph" ) { u.tokens[0].raw = u.tokens[0].raw.replace( this.rules.other.listReplaceTask, "" ), u.tokens[0].text = u.tokens[0].text.replace( this.rules.other.listReplaceTask, "" );for ( let c = this.lexer.inlineQueue.length - 1;c >= 0;c-- ) if ( this.rules.other.listIsTask.test( this.lexer.inlineQueue[c].src ) ) { this.lexer.inlineQueue[c].src = this.lexer.inlineQueue[c].src.replace( this.rules.other.listReplaceTask, "" );break } } let p = this.rules.other.listTaskCheckbox.exec( u.raw );if ( p ) { let c = { type: "checkbox", raw: `${p[0] } `, checked: p[0] !== "[ ]" };u.checked = c.checked, i.loose ? u.tokens[0] && ["paragraph", "text"].includes( u.tokens[0].type ) && "tokens" in u.tokens[0] && u.tokens[0].tokens ? ( u.tokens[0].raw = c.raw + u.tokens[0].raw, u.tokens[0].text = c.raw + u.tokens[0].text, u.tokens[0].tokens.unshift( c ) ) : u.tokens.unshift({ type: "paragraph", raw: c.raw, text: c.raw, tokens: [c] }) : u.tokens.unshift( c ) } } if ( !i.loose ) { let p = u.tokens.filter( g => { return g.type === "space" }); let c = p.length > 0 && p.some( g => { return this.rules.other.anyLine.test( g.raw ) });i.loose = c } } if ( i.loose ) for ( let u of i.items ) { u.loose = !0;for ( let p of u.tokens )p.type === "text" && ( p.type = "paragraph" ) } return i
			}
		}html ( e ) { let t = this.rules.block.html.exec( e );if ( t ) return { type: "html", block: !0, raw: t[0], pre: t[1] === "pre" || t[1] === "script" || t[1] === "style", text: t[0] } }def ( e ) { let t = this.rules.block.def.exec( e );if ( t ) { let n = t[1].toLowerCase().replace( this.rules.other.multipleSpaceGlobal, " " ); let r = t[2] ? t[2].replace( this.rules.other.hrefBrackets, "$1" ).replace( this.rules.inline.anyPunctuation, "$1" ) : ""; let i = t[3] ? t[3].substring( 1, t[3].length - 1 ).replace( this.rules.inline.anyPunctuation, "$1" ) : t[3];return { type: "def", tag: n, raw: t[0], href: r, title: i } } }table ( e )
		{
			let t = this.rules.block.table.exec( e );if ( !t || !this.rules.other.tableDelimiter.test( t[2] ) ) return;let n = V( t[1] ); let r = t[2].replace( this.rules.other.tableAlignChars, "" ).split( "|" ); let i = t[3]?.trim() ? t[3].replace( this.rules.other.tableRowBlankLine, "" ).split( `
` ) : []; let s = { type: "table", raw: t[0], header: [], align: [], rows: [] };if ( n.length === r.length ) { for ( let a of r ) this.rules.other.tableAlignRight.test( a ) ? s.align.push( "right" ) : this.rules.other.tableAlignCenter.test( a ) ? s.align.push( "center" ) : this.rules.other.tableAlignLeft.test( a ) ? s.align.push( "left" ) : s.align.push( null );for ( let a = 0;a < n.length;a++ )s.header.push({ text: n[a], tokens: this.lexer.inline( n[a] ), header: !0, align: s.align[a] });for ( let a of i )s.rows.push( V( a, s.header.length ).map( ( o, u ) => { return { text: o, tokens: this.lexer.inline( o ), header: !1, align: s.align[u] } }) );return s }
		}lheading ( e ) { let t = this.rules.block.lheading.exec( e );if ( t ) return { type: "heading", raw: t[0], depth: t[2].charAt( 0 ) === "=" ? 1 : 2, text: t[1], tokens: this.lexer.inline( t[1] ) } }paragraph ( e )
		{
			let t = this.rules.block.paragraph.exec( e );if ( t )
			{
				let n = t[1].charAt( t[1].length - 1 ) === `
` ? t[1].slice( 0, -1 ) : t[1];return { type: "paragraph", raw: t[0], text: n, tokens: this.lexer.inline( n ) }
			}
		}text ( e ) { let t = this.rules.block.text.exec( e );if ( t ) return { type: "text", raw: t[0], text: t[0], tokens: this.lexer.inline( t[0] ) } }escape ( e ) { let t = this.rules.inline.escape.exec( e );if ( t ) return { type: "escape", raw: t[0], text: t[1] } }tag ( e ) { let t = this.rules.inline.tag.exec( e );if ( t ) return !this.lexer.state.inLink && this.rules.other.startATag.test( t[0] ) ? this.lexer.state.inLink = !0 : this.lexer.state.inLink && this.rules.other.endATag.test( t[0] ) && ( this.lexer.state.inLink = !1 ), !this.lexer.state.inRawBlock && this.rules.other.startPreScriptTag.test( t[0] ) ? this.lexer.state.inRawBlock = !0 : this.lexer.state.inRawBlock && this.rules.other.endPreScriptTag.test( t[0] ) && ( this.lexer.state.inRawBlock = !1 ), { type: "html", raw: t[0], inLink: this.lexer.state.inLink, inRawBlock: this.lexer.state.inRawBlock, block: !1, text: t[0] } }link ( e )
		{
			let t = this.rules.inline.link.exec( e );if ( t )
			{
				let n = t[2].trim();if ( !this.options.pedantic && this.rules.other.startAngleBracket.test( n ) ) { if ( !this.rules.other.endAngleBracket.test( n ) ) return;let s = z( n.slice( 0, -1 ), "\\" );if ( ( n.length - s.length ) % 2 === 0 ) return }
				else { let s = ge( t[2], "()" );if ( s === -2 ) return;if ( s > -1 ) { let o = ( t[0].indexOf( "!" ) === 0 ? 5 : 4 ) + t[1].length + s;t[2] = t[2].substring( 0, s ), t[0] = t[0].substring( 0, o ).trim(), t[3] = "" } } let r = t[2]; let i = "";if ( this.options.pedantic ) { let s = this.rules.other.pedanticHrefTitle.exec( r );s && ( r = s[1], i = s[3] ) }
				else i = t[3] ? t[3].slice( 1, -1 ) : "";return r = r.trim(), this.rules.other.startAngleBracket.test( r ) && ( this.options.pedantic && !this.rules.other.endAngleBracket.test( n ) ? r = r.slice( 1 ) : r = r.slice( 1, -1 ) ), fe( t, { href: r && r.replace( this.rules.inline.anyPunctuation, "$1" ), title: i && i.replace( this.rules.inline.anyPunctuation, "$1" ) }, t[0], this.lexer, this.rules )
			}
		}reflink ( e, t ) { let n;if ( ( n = this.rules.inline.reflink.exec( e ) ) || ( n = this.rules.inline.nolink.exec( e ) ) ) { let r = ( n[2] || n[1] ).replace( this.rules.other.multipleSpaceGlobal, " " ); let i = t[r.toLowerCase()];if ( !i ) { let s = n[0].charAt( 0 );return { type: "text", raw: s, text: s } } return fe( n, i, n[0], this.lexer, this.rules ) } }emStrong ( e, t, n = "" )
		{
			let r = this.rules.inline.emStrongLDelim.exec( e );if ( !r || r[3] && n.match( this.rules.other.unicodeAlphaNumeric ) ) return;if ( !( r[1] || r[2] || "" ) || !n || this.rules.inline.punctuation.exec( n ) )
			{
				let s = [...r[0]].length - 1; let a; let o; let u = s; let p = 0; let c = r[0][0] === "*" ? this.rules.inline.emStrongRDelimAst : this.rules.inline.emStrongRDelimUnd;for ( c.lastIndex = 0, t = t.slice( -1 * e.length + s );( r = c.exec( t ) ) != null; )
				{
					if ( a = r[1] || r[2] || r[3] || r[4] || r[5] || r[6], !a ) continue;if ( o = [...a].length, r[3] || r[4] ) { u += o;continue }
					else if ( ( r[5] || r[6] ) && s % 3 && !( ( s + o ) % 3 ) ) { p += o;continue } if ( u -= o, u > 0 ) continue;o = Math.min( o, o + u + p );let g = [...r[0]][0].length; let h = e.slice( 0, s + r.index + g + o );if ( Math.min( s, o ) % 2 ) { let f = h.slice( 1, -1 );return { type: "em", raw: h, text: f, tokens: this.lexer.inlineTokens( f ) } } let R = h.slice( 2, -2 );return { type: "strong", raw: h, text: R, tokens: this.lexer.inlineTokens( R ) }
				}
			}
		}codespan ( e ) { let t = this.rules.inline.code.exec( e );if ( t ) { let n = t[2].replace( this.rules.other.newLineCharGlobal, " " ); let r = this.rules.other.nonSpaceChar.test( n ); let i = this.rules.other.startingSpaceChar.test( n ) && this.rules.other.endingSpaceChar.test( n );return r && i && ( n = n.substring( 1, n.length - 1 ) ), { type: "codespan", raw: t[0], text: n } } }br ( e ) { let t = this.rules.inline.br.exec( e );if ( t ) return { type: "br", raw: t[0] } }del ( e ) { let t = this.rules.inline.del.exec( e );if ( t ) return { type: "del", raw: t[0], text: t[2], tokens: this.lexer.inlineTokens( t[2] ) } }autolink ( e ) { let t = this.rules.inline.autolink.exec( e );if ( t ) { let n; let r;return t[2] === "@" ? ( n = t[1], r = `mailto:${ n}` ) : ( n = t[1], r = n ), { type: "link", raw: t[0], text: n, href: r, tokens: [{ type: "text", raw: n, text: n }] } } }url ( e ) { let t;if ( t = this.rules.inline.url.exec( e ) ) { let n; let r;if ( t[2] === "@" )n = t[0], r = `mailto:${ n}`;else { let i;do i = t[0], t[0] = this.rules.inline._backpedal.exec( t[0] )?.[0] ?? "";while ( i !== t[0] );n = t[0], t[1] === "www." ? r = `http://${ t[0]}` : r = t[0] } return { type: "link", raw: t[0], text: n, href: r, tokens: [{ type: "text", raw: n, text: n }] } } }inlineText ( e ) { let t = this.rules.inline.text.exec( e );if ( t ) { let n = this.lexer.state.inRawBlock;return { type: "text", raw: t[0], text: t[0], escaped: n } } }
	};var x = class l
	{
		tokens;options;state;inlineQueue;tokenizer;constructor ( e ) { this.tokens = [], this.tokens.links = Object.create( null ), this.options = e || T, this.options.tokenizer = this.options.tokenizer || new y, this.tokenizer = this.options.tokenizer, this.tokenizer.options = this.options, this.tokenizer.lexer = this, this.inlineQueue = [], this.state = { inLink: !1, inRawBlock: !1, top: !0 };let t = { other: m, block: B.normal, inline: M.normal };this.options.pedantic ? ( t.block = B.pedantic, t.inline = M.pedantic ) : this.options.gfm && ( t.block = B.gfm, this.options.breaks ? t.inline = M.breaks : t.inline = M.gfm ), this.tokenizer.rules = t } static get rules () { return { block: B, inline: M } } static lex ( e, t ) { return new l( t ).lex( e ) } static lexInline ( e, t ) { return new l( t ).inlineTokens( e ) }lex ( e )
		{
			e = e.replace( m.carriageReturn, `
` ), this.blockTokens( e, this.tokens );for ( let t = 0;t < this.inlineQueue.length;t++ ) { let n = this.inlineQueue[t];this.inlineTokens( n.src, n.tokens ) } return this.inlineQueue = [], this.tokens
		}blockTokens ( e, t = [], n = !1 )
		{
			for ( this.options.pedantic && ( e = e.replace( m.tabCharGlobal, "    " ).replace( m.spaceLine, "" ) );e; )
			{
				let r;if ( this.options.extensions?.block?.some( s => { return ( r = s.call({ lexer: this }, e, t ) ) ? ( e = e.substring( r.raw.length ), t.push( r ), !0 ) : !1 }) ) continue;if ( r = this.tokenizer.space( e ) )
				{
					e = e.substring( r.raw.length );let s = t.at( -1 );r.raw.length === 1 && s !== void 0 ? s.raw += `
` : t.push( r );continue
				} if ( r = this.tokenizer.code( e ) )
				{
					e = e.substring( r.raw.length );let s = t.at( -1 );s?.type === "paragraph" || s?.type === "text" ? ( s.raw += ( s.raw.endsWith( `
` ) ? "" : `
` ) + r.raw, s.text += `
${ r.text}`, this.inlineQueue.at( -1 ).src = s.text ) : t.push( r );continue
				} if ( r = this.tokenizer.fences( e ) ) { e = e.substring( r.raw.length ), t.push( r );continue } if ( r = this.tokenizer.heading( e ) ) { e = e.substring( r.raw.length ), t.push( r );continue } if ( r = this.tokenizer.hr( e ) ) { e = e.substring( r.raw.length ), t.push( r );continue } if ( r = this.tokenizer.blockquote( e ) ) { e = e.substring( r.raw.length ), t.push( r );continue } if ( r = this.tokenizer.list( e ) ) { e = e.substring( r.raw.length ), t.push( r );continue } if ( r = this.tokenizer.html( e ) ) { e = e.substring( r.raw.length ), t.push( r );continue } if ( r = this.tokenizer.def( e ) )
				{
					e = e.substring( r.raw.length );let s = t.at( -1 );s?.type === "paragraph" || s?.type === "text" ? ( s.raw += ( s.raw.endsWith( `
` ) ? "" : `
` ) + r.raw, s.text += `
${ r.raw}`, this.inlineQueue.at( -1 ).src = s.text ) : this.tokens.links[r.tag] || ( this.tokens.links[r.tag] = { href: r.href, title: r.title }, t.push( r ) );continue
				} if ( r = this.tokenizer.table( e ) ) { e = e.substring( r.raw.length ), t.push( r );continue } if ( r = this.tokenizer.lheading( e ) ) { e = e.substring( r.raw.length ), t.push( r );continue } let i = e;if ( this.options.extensions?.startBlock ) { let s = 1 / 0; let a = e.slice( 1 ); let o;this.options.extensions.startBlock.forEach( u => { o = u.call({ lexer: this }, a ), typeof o == "number" && o >= 0 && ( s = Math.min( s, o ) ) }), s < 1 / 0 && s >= 0 && ( i = e.substring( 0, s + 1 ) ) } if ( this.state.top && ( r = this.tokenizer.paragraph( i ) ) )
				{
					let s = t.at( -1 );n && s?.type === "paragraph" ? ( s.raw += ( s.raw.endsWith( `
` ) ? "" : `
` ) + r.raw, s.text += `
${ r.text}`, this.inlineQueue.pop(), this.inlineQueue.at( -1 ).src = s.text ) : t.push( r ), n = i.length !== e.length, e = e.substring( r.raw.length );continue
				} if ( r = this.tokenizer.text( e ) )
				{
					e = e.substring( r.raw.length );let s = t.at( -1 );s?.type === "text" ? ( s.raw += ( s.raw.endsWith( `
` ) ? "" : `
` ) + r.raw, s.text += `
${ r.text}`, this.inlineQueue.pop(), this.inlineQueue.at( -1 ).src = s.text ) : t.push( r );continue
				} if ( e )
				{
					let s = `Infinite loop on byte: ${ e.charCodeAt( 0 )}`;if ( this.options.silent ) { console.error( s );break }
					else throw new Error( s )
				}
			} return this.state.top = !0, t
		}inline ( e, t = [] ) { return this.inlineQueue.push({ src: e, tokens: t }), t }inlineTokens ( e, t = [] )
		{
			let n = e; let r = null;if ( this.tokens.links ) { let o = Object.keys( this.tokens.links );if ( o.length > 0 ) for ( ;( r = this.tokenizer.rules.inline.reflinkSearch.exec( n ) ) != null; )o.includes( r[0].slice( r[0].lastIndexOf( "[" ) + 1, -1 ) ) && ( n = `${n.slice( 0, r.index ) }[${ "a".repeat( r[0].length - 2 ) }]${ n.slice( this.tokenizer.rules.inline.reflinkSearch.lastIndex )}` ) } for ( ;( r = this.tokenizer.rules.inline.anyPunctuation.exec( n ) ) != null; )n = `${n.slice( 0, r.index ) }++${ n.slice( this.tokenizer.rules.inline.anyPunctuation.lastIndex )}`;let i;for ( ;( r = this.tokenizer.rules.inline.blockSkip.exec( n ) ) != null; )i = r[2] ? r[2].length : 0, n = `${n.slice( 0, r.index + i ) }[${ "a".repeat( r[0].length - i - 2 ) }]${ n.slice( this.tokenizer.rules.inline.blockSkip.lastIndex )}`;n = this.options.hooks?.emStrongMask?.call({ lexer: this }, n ) ?? n;let s = !1; let a = "";for ( ;e; )
			{
				s || ( a = "" ), s = !1;let o;if ( this.options.extensions?.inline?.some( p => { return ( o = p.call({ lexer: this }, e, t ) ) ? ( e = e.substring( o.raw.length ), t.push( o ), !0 ) : !1 }) ) continue;if ( o = this.tokenizer.escape( e ) ) { e = e.substring( o.raw.length ), t.push( o );continue } if ( o = this.tokenizer.tag( e ) ) { e = e.substring( o.raw.length ), t.push( o );continue } if ( o = this.tokenizer.link( e ) ) { e = e.substring( o.raw.length ), t.push( o );continue } if ( o = this.tokenizer.reflink( e, this.tokens.links ) ) { e = e.substring( o.raw.length );let p = t.at( -1 );o.type === "text" && p?.type === "text" ? ( p.raw += o.raw, p.text += o.text ) : t.push( o );continue } if ( o = this.tokenizer.emStrong( e, n, a ) ) { e = e.substring( o.raw.length ), t.push( o );continue } if ( o = this.tokenizer.codespan( e ) ) { e = e.substring( o.raw.length ), t.push( o );continue } if ( o = this.tokenizer.br( e ) ) { e = e.substring( o.raw.length ), t.push( o );continue } if ( o = this.tokenizer.del( e ) ) { e = e.substring( o.raw.length ), t.push( o );continue } if ( o = this.tokenizer.autolink( e ) ) { e = e.substring( o.raw.length ), t.push( o );continue } if ( !this.state.inLink && ( o = this.tokenizer.url( e ) ) ) { e = e.substring( o.raw.length ), t.push( o );continue } let u = e;if ( this.options.extensions?.startInline ) { let p = 1 / 0; let c = e.slice( 1 ); let g;this.options.extensions.startInline.forEach( h => { g = h.call({ lexer: this }, c ), typeof g == "number" && g >= 0 && ( p = Math.min( p, g ) ) }), p < 1 / 0 && p >= 0 && ( u = e.substring( 0, p + 1 ) ) } if ( o = this.tokenizer.inlineText( u ) ) { e = e.substring( o.raw.length ), o.raw.slice( -1 ) !== "_" && ( a = o.raw.slice( -1 ) ), s = !0;let p = t.at( -1 );p?.type === "text" ? ( p.raw += o.raw, p.text += o.text ) : t.push( o );continue } if ( e )
				{
					let p = `Infinite loop on byte: ${ e.charCodeAt( 0 )}`;if ( this.options.silent ) { console.error( p );break }
					else throw new Error( p )
				}
			} return t
		}
	};var P = class
	{
		options;parser;constructor ( e ) { this.options = e || T }space ( e ) { return "" }code ({ text: e, lang: t, escaped: n })
		{
			let r = ( t || "" ).match( m.notSpaceStart )?.[0]; let i = `${e.replace( m.endingNewline, "" ) }
`;return r ? `<pre><code class="language-${ w( r ) }">${ n ? i : w( i, !0 ) }</code></pre>
` : `<pre><code>${ n ? i : w( i, !0 ) }</code></pre>
`
		}blockquote ({ tokens: e })
		{
			return `<blockquote>
${this.parser.parse( e )}</blockquote>
`
		}html ({ text: e }) { return e }def ( e ) { return "" }heading ({ tokens: e, depth: t })
		{
			return `<h${t}>${this.parser.parseInline( e )}</h${t}>
`
		}hr ( e )
		{
			return `<hr>
`
		}list ( e )
		{
			let t = e.ordered; let n = e.start; let r = "";for ( let a = 0;a < e.items.length;a++ ) { let o = e.items[a];r += this.listitem( o ) } let i = t ? "ol" : "ul"; let s = t && n !== 1 ? ` start="${ n }"` : "";return `<${ i }${s }>
${ r }</${ i }>
`
		}listitem ( e )
		{
			return `<li>${this.parser.parse( e.tokens )}</li>
`
		}checkbox ({ checked: e }) { return `<input ${ e ? "checked=\"\" " : "" }disabled="" type="checkbox"> ` }paragraph ({ tokens: e })
		{
			return `<p>${this.parser.parseInline( e )}</p>
`
		}table ( e )
		{
			let t = ""; let n = "";for ( let i = 0;i < e.header.length;i++ )n += this.tablecell( e.header[i] );t += this.tablerow({ text: n });let r = "";for ( let i = 0;i < e.rows.length;i++ ) { let s = e.rows[i];n = "";for ( let a = 0;a < s.length;a++ )n += this.tablecell( s[a] );r += this.tablerow({ text: n }) } return r && ( r = `<tbody>${r}</tbody>` ), `<table>
<thead>
${ t }</thead>
${ r }</table>
`
		}tablerow ({ text: e })
		{
			return `<tr>
${e}</tr>
`
		}tablecell ( e )
		{
			let t = this.parser.parseInline( e.tokens ); let n = e.header ? "th" : "td";return `${( e.align ? `<${n} align="${e.align}">` : `<${n}>` ) + t }</${n}>
`
		}strong ({ tokens: e }) { return `<strong>${this.parser.parseInline( e )}</strong>` }em ({ tokens: e }) { return `<em>${this.parser.parseInline( e )}</em>` }codespan ({ text: e }) { return `<code>${w( e, !0 )}</code>` }br ( e ) { return "<br>" }del ({ tokens: e }) { return `<del>${this.parser.parseInline( e )}</del>` }link ({ href: e, title: t, tokens: n }) { let r = this.parser.parseInline( n ); let i = J( e );if ( i === null ) return r;e = i;let s = `<a href="${ e }"`;return t && ( s += ` title="${ w( t ) }"` ), s += `>${ r }</a>`, s }image ({ href: e, title: t, text: n, tokens: r }) { r && ( n = this.parser.parseInline( r, this.parser.textRenderer ) );let i = J( e );if ( i === null ) return w( n );e = i;let s = `<img src="${e}" alt="${n}"`;return t && ( s += ` title="${w( t )}"` ), s += ">", s }text ( e ) { return "tokens" in e && e.tokens ? this.parser.parseInline( e.tokens ) : "escaped" in e && e.escaped ? e.text : w( e.text ) }
	};var $ = class {strong ({ text: e }) { return e }em ({ text: e }) { return e }codespan ({ text: e }) { return e }del ({ text: e }) { return e }html ({ text: e }) { return e }text ({ text: e }) { return e }link ({ text: e }) { return `${ e}` }image ({ text: e }) { return `${ e}` }br () { return "" }checkbox ({ raw: e }) { return e }};var b = class l {options;renderer;textRenderer;constructor ( e ) { this.options = e || T, this.options.renderer = this.options.renderer || new P, this.renderer = this.options.renderer, this.renderer.options = this.options, this.renderer.parser = this, this.textRenderer = new $ } static parse ( e, t ) { return new l( t ).parse( e ) } static parseInline ( e, t ) { return new l( t ).parseInline( e ) }parse ( e ) { let t = "";for ( let n = 0;n < e.length;n++ ) { let r = e[n];if ( this.options.extensions?.renderers?.[r.type] ) { let s = r; let a = this.options.extensions.renderers[s.type].call({ parser: this }, s );if ( a !== !1 || !["space", "hr", "heading", "code", "table", "blockquote", "list", "html", "def", "paragraph", "text"].includes( s.type ) ) { t += a || "";continue } } let i = r;switch ( i.type ) { case "space":{ t += this.renderer.space( i );break } case "hr":{ t += this.renderer.hr( i );break } case "heading":{ t += this.renderer.heading( i );break } case "code":{ t += this.renderer.code( i );break } case "table":{ t += this.renderer.table( i );break } case "blockquote":{ t += this.renderer.blockquote( i );break } case "list":{ t += this.renderer.list( i );break } case "checkbox":{ t += this.renderer.checkbox( i );break } case "html":{ t += this.renderer.html( i );break } case "def":{ t += this.renderer.def( i );break } case "paragraph":{ t += this.renderer.paragraph( i );break } case "text":{ t += this.renderer.text( i );break } default:{ let s = `Token with "${ i.type }" type was not found.`;if ( this.options.silent ) return console.error( s ), "";throw new Error( s ) } } } return t }parseInline ( e, t = this.renderer ) { let n = "";for ( let r = 0;r < e.length;r++ ) { let i = e[r];if ( this.options.extensions?.renderers?.[i.type] ) { let a = this.options.extensions.renderers[i.type].call({ parser: this }, i );if ( a !== !1 || !["escape", "html", "link", "image", "strong", "em", "codespan", "br", "del", "text"].includes( i.type ) ) { n += a || "";continue } } let s = i;switch ( s.type ) { case "escape":{ n += t.text( s );break } case "html":{ n += t.html( s );break } case "link":{ n += t.link( s );break } case "image":{ n += t.image( s );break } case "checkbox":{ n += t.checkbox( s );break } case "strong":{ n += t.strong( s );break } case "em":{ n += t.em( s );break } case "codespan":{ n += t.codespan( s );break } case "br":{ n += t.br( s );break } case "del":{ n += t.del( s );break } case "text":{ n += t.text( s );break } default:{ let a = `Token with "${ s.type }" type was not found.`;if ( this.options.silent ) return console.error( a ), "";throw new Error( a ) } } } return n }};var S = class {options;block;constructor ( e ) { this.options = e || T } static passThroughHooks = new Set( ["preprocess", "postprocess", "processAllTokens", "emStrongMask"] );static passThroughHooksRespectAsync = new Set( ["preprocess", "postprocess", "processAllTokens"] );preprocess ( e ) { return e }postprocess ( e ) { return e }processAllTokens ( e ) { return e }emStrongMask ( e ) { return e }provideLexer () { return this.block ? x.lex : x.lexInline }provideParser () { return this.block ? b.parse : b.parseInline }};var A = class
	{
		defaults = _();options = this.setOptions;parse = this.parseMarkdown( !0 );parseInline = this.parseMarkdown( !1 );Parser = b;Renderer = P;TextRenderer = $;Lexer = x;Tokenizer = y;Hooks = S;constructor ( ...e ) { this.use( ...e ) }walkTokens ( e, t ) { let n = [];for ( let r of e ) switch ( n = n.concat( t.call( this, r ) ), r.type ) { case "table":{ let i = r;for ( let s of i.header )n = n.concat( this.walkTokens( s.tokens, t ) );for ( let s of i.rows ) for ( let a of s )n = n.concat( this.walkTokens( a.tokens, t ) );break } case "list":{ let i = r;n = n.concat( this.walkTokens( i.items, t ) );break } default:{ let i = r;this.defaults.extensions?.childTokens?.[i.type] ? this.defaults.extensions.childTokens[i.type].forEach( s => { let a = i[s].flat( 1 / 0 );n = n.concat( this.walkTokens( a, t ) ) }) : i.tokens && ( n = n.concat( this.walkTokens( i.tokens, t ) ) ) } } return n }use ( ...e ) { let t = this.defaults.extensions || { renderers: {}, childTokens: {} };return e.forEach( n => { let r = { ...n };if ( r.async = this.defaults.async || r.async || !1, n.extensions && ( n.extensions.forEach( i => { if ( !i.name ) throw new Error( "extension name required" );if ( "renderer" in i ) { let s = t.renderers[i.name];s ? t.renderers[i.name] = function ( ...a ) { let o = i.renderer.apply( this, a );return o === !1 && ( o = s.apply( this, a ) ), o } : t.renderers[i.name] = i.renderer } if ( "tokenizer" in i ) { if ( !i.level || i.level !== "block" && i.level !== "inline" ) throw new Error( "extension level must be 'block' or 'inline'" );let s = t[i.level];s ? s.unshift( i.tokenizer ) : t[i.level] = [i.tokenizer], i.start && ( i.level === "block" ? t.startBlock ? t.startBlock.push( i.start ) : t.startBlock = [i.start] : i.level === "inline" && ( t.startInline ? t.startInline.push( i.start ) : t.startInline = [i.start] ) ) }"childTokens" in i && i.childTokens && ( t.childTokens[i.name] = i.childTokens ) }), r.extensions = t ), n.renderer ) { let i = this.defaults.renderer || new P( this.defaults );for ( let s in n.renderer ) { if ( !( s in i ) ) throw new Error( `renderer '${s}' does not exist` );if ( ["options", "parser"].includes( s ) ) continue;let a = s; let o = n.renderer[a]; let u = i[a];i[a] = ( ...p ) => { let c = o.apply( i, p );return c === !1 && ( c = u.apply( i, p ) ), c || "" } }r.renderer = i } if ( n.tokenizer ) { let i = this.defaults.tokenizer || new y( this.defaults );for ( let s in n.tokenizer ) { if ( !( s in i ) ) throw new Error( `tokenizer '${s}' does not exist` );if ( ["options", "rules", "lexer"].includes( s ) ) continue;let a = s; let o = n.tokenizer[a]; let u = i[a];i[a] = ( ...p ) => { let c = o.apply( i, p );return c === !1 && ( c = u.apply( i, p ) ), c } }r.tokenizer = i } if ( n.hooks ) { let i = this.defaults.hooks || new S;for ( let s in n.hooks ) { if ( !( s in i ) ) throw new Error( `hook '${s}' does not exist` );if ( ["options", "block"].includes( s ) ) continue;let a = s; let o = n.hooks[a]; let u = i[a];S.passThroughHooks.has( s ) ? i[a] = p => { if ( this.defaults.async && S.passThroughHooksRespectAsync.has( s ) ) return ( async () => { let g = await o.call( i, p );return u.call( i, g ) })();let c = o.call( i, p );return u.call( i, c ) } : i[a] = ( ...p ) => { if ( this.defaults.async ) return ( async () => { let g = await o.apply( i, p );return g === !1 && ( g = await u.apply( i, p ) ), g })();let c = o.apply( i, p );return c === !1 && ( c = u.apply( i, p ) ), c } }r.hooks = i } if ( n.walkTokens ) { let i = this.defaults.walkTokens; let s = n.walkTokens;r.walkTokens = function ( a ) { let o = [];return o.push( s.call( this, a ) ), i && ( o = o.concat( i.call( this, a ) ) ), o } } this.defaults = { ...this.defaults, ...r } }), this }setOptions ( e ) { return this.defaults = { ...this.defaults, ...e }, this }lexer ( e, t ) { return x.lex( e, t ?? this.defaults ) }parser ( e, t ) { return b.parse( e, t ?? this.defaults ) }parseMarkdown ( e )
		{
			return ( n, r ) =>
			{
				let i = { ...r }; let s = { ...this.defaults, ...i }; let a = this.onError( !!s.silent, !!s.async );if ( this.defaults.async === !0 && i.async === !1 ) return a( new Error( "marked(): The async option was set to true by an extension. Remove async: false from the parse options object to return a Promise." ) );if ( typeof n > "u" || n === null ) return a( new Error( "marked(): input parameter is undefined or null" ) );if ( typeof n != "string" ) return a( new Error( `marked(): input parameter is of type ${ Object.prototype.toString.call( n ) }, string expected` ) );if ( s.hooks && ( s.hooks.options = s, s.hooks.block = e ), s.async ) return ( async () => { let o = s.hooks ? await s.hooks.preprocess( n ) : n; let p = await ( s.hooks ? await s.hooks.provideLexer() : e ? x.lex : x.lexInline )( o, s ); let c = s.hooks ? await s.hooks.processAllTokens( p ) : p;s.walkTokens && await Promise.all( this.walkTokens( c, s.walkTokens ) );let h = await ( s.hooks ? await s.hooks.provideParser() : e ? b.parse : b.parseInline )( c, s );return s.hooks ? await s.hooks.postprocess( h ) : h })().catch( a );try { s.hooks && ( n = s.hooks.preprocess( n ) );let u = ( s.hooks ? s.hooks.provideLexer() : e ? x.lex : x.lexInline )( n, s );s.hooks && ( u = s.hooks.processAllTokens( u ) ), s.walkTokens && this.walkTokens( u, s.walkTokens );let c = ( s.hooks ? s.hooks.provideParser() : e ? b.parse : b.parseInline )( u, s );return s.hooks && ( c = s.hooks.postprocess( c ) ), c }
				catch ( o ) { return a( o ) }
			}
		}onError ( e, t )
		{
			return n =>
			{
				if ( n.message += `
Please report this to https://github.com/markedjs/marked.`, e ) { let r = `<p>An error occurred:</p><pre>${ w( `${n.message }`, !0 ) }</pre>`;return t ? Promise.resolve( r ) : r } if ( t ) return Promise.reject( n );throw n
			}
		}
	};var L = new A;function d ( l, e ) { return L.parse( l, e ) }d.options = d.setOptions = function ( l ) { return L.setOptions( l ), d.defaults = L.defaults, G( d.defaults ), d };d.getDefaults = _;d.defaults = T;d.use = function ( ...l ) { return L.use( ...l ), d.defaults = L.defaults, G( d.defaults ), d };d.walkTokens = function ( l, e ) { return L.walkTokens( l, e ) };d.parseInline = L.parseInline;d.Parser = b;d.parser = b.parse;d.Renderer = P;d.TextRenderer = $;d.Lexer = x;d.lexer = x.lex;d.Tokenizer = y;d.Hooks = S;d.parse = d;var it = d.options; var ot = d.setOptions; var at = d.use; var lt = d.walkTokens; var ut = d.parseInline; var pt = d; var ct = b.parse; var ht = x.lex;

	if ( __exports != exports )module.exports = exports;return module.exports
}) );
//# sourceMappingURL=marked.umd.js.map
</file>

<file path="docs/.vitepress/config.mjs">
import { defineConfig } from "vitepress"

export default defineConfig({
	base: "/Unified-AI-Router/",
	server: {
   	host: true,
	},
	title: "Unified AI Router",
	description: "OpenAI-compatible router with multi-provider fallback, supporting both Chat Completions and Responses API.",
	head: [
		["link", { rel: "icon", href: "favicon.png" }],
		["link", { rel: "icon", type: "image/png", href: "favicon.png" }],
		["link", { rel: "apple-touch-icon", href: "favicon.png" }]
	 ],
	themeConfig: {
		nav: [
			{ text: "Home", link: "/" },
			{ text: "Quickstart", link: "/quickstart" },
			{ text: "Configuration", link: "/configuration" },
			{ text: "SDK Usage", link: "/sdk-usage" },
			{ text: "API Examples", link: "/api-examples" },
			{ text: "Providers", link: "/providers" },
			{ text: "Testing", link: "/testing" },
			{ text: "Deployment", link: "/deployment" }
		],
		sidebar: [
			{
				text: "Getting Started",
				items: [
					{ text: "Quickstart", link: "/quickstart" },
					{ text: "Configuration", link: "/configuration" }
				]
			},
			{
				text: "Usage",
				items: [
					{ text: "SDK Usage", link: "/sdk-usage" },
					{ text: "API Examples", link: "/api-examples" },
					{ text: "Providers", link: "/providers" }
				]
			},
			{
				text: "Testing & Deployment",
				items: [
					{ text: "Testing Guide", link: "/testing" },
					{ text: "Deployment Guide", link: "/deployment" }
				]
			}
		],
		socialLinks: [
			{ icon: "github", link: "https://github.com/mlibre/Unified-AI-Router" },
			{ icon: "npm", link: "https://www.npmjs.com/package/unified-ai-router" }

		]
	}
})
</file>

<file path="docs/api-examples.md">
# 🚀 API Examples

Complete examples for Chat Completions and Responses API with streaming and tool calling.

## 💬 Chat Completions

### Basic Request

```bash
curl -X POST http://localhost:3000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "any-model",
    "messages": [
      {"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "Hello!"}
    ],
    "temperature": 0.7,
    "stream": false
  }'
```

### 🌊 Streaming Response

```bash
curl -X POST http://localhost:3000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "any-model",
    "messages": [{"role": "user", "content": "Say hello in exactly 3 words."}],
    "stream": true
  }' \
  --no-buffer
```

### 🛠️ Tool Calling

```bash
curl -X POST http://localhost:3000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "no_need",
    "messages": [{"role": "user", "content": "How is weather in Tehran? Use tools."}],
    "tools": [
      {
        "type": "function",
        "function": {
          "name": "get_weather",
          "description": "Get weather for a city",
          "parameters": {
            "type": "object",
            "properties": {
              "city": {"type": "string", "description": "City name"}
            },
            "required": ["city"]
          },
          "strict": true
        }
      }
    ],
    "stream": true
  }'
```

## 🗣️ Responses API

### Basic Request

```bash
curl -X POST http://localhost:3000/v1/responses \
  -H "Content-Type: application/json" \
  -d '{
    "model": "any-model",
    "input": "Tell me about AI.",
    "temperature": 0.7
  }'
```

### 🌊 Streaming Response

```bash
curl -X POST http://localhost:3000/v1/responses \
  -H "Content-Type: application/json" \
  -d '{
    "model": "any-model",
    "input": "Write a short poem.",
    "stream": true
  }' \
  --no-buffer
```

### 🛠️ Tool Calling

```bash
curl -X POST http://localhost:3000/v1/responses \
  -H "Content-Type: application/json" \
  -d '{
    "model": "no_need",
    "input": "Calculate 15% tip on $85 and check weather in Tehran.",
    "tools": [
      {
        "type": "function",
        "name": "calculate_tip",
        "description": "Calculate tip amount",
        "parameters": {
          "type": "object",
          "properties": {
            "amount": {"type": "number"},
            "percentage": {"type": "number"}
          },
          "required": ["amount", "percentage"]
        }
      },
      {
        "type": "function",
        "name": "get_weather",
        "description": "Get weather for a city",
        "parameters": {
          "type": "object",
          "properties": {
            "city": {"type": "string"}
          },
          "required": ["city"]
        }
      }
    ]
  }'
```
</file>

<file path="docs/index.md">
---
layout: home

hero:
  name: "Unified AI Router"
  text: "OpenAI-compatible server with multi-provider fallback"
  tagline: "Responses API, Chat Completions, streaming, tool-calling, automatic fallback, circuit breakers."
  actions:
    - theme: brand
      text: Quickstart
      link: /quickstart
    - theme: alt
      text: Configuration
      link: /configuration

features:
  - title: Multi-provider fallback
    details: Automatic failover between OpenAI, OpenRouter, Gemini, and more.
  - title: Circuit breaker protection
    details: Prevents cascading failures with automatic circuit breaking.
  - title: OpenAI-compatible
    details: Drop-in replacement for Chat Completions and Responses API.
  - title: Streaming & tools
    details: SSE streaming and tool-calling support.
  - title: Production ready
    details: Deploy anywhere with npm start.
---
</file>

<file path="docs/testing.md">
# 🧪 Testing

Comprehensive testing guide for Unified AI Router.

## 📋 Test Overview

The project includes tests for both the AIRouter library and the OpenAI-compatible server endpoints.

## 🚀 Running Tests

### Prerequisites

```bash
# Install dependencies
npm install

# Configure environment
cp .env.example .env
# Add your API keys to .env
```

### 🖥️ Start the Server

```bash
# Start server in background
npm start &
```

### 💬 Chat Completions Tests

```bash
# Basic chat functionality (streaming)
node tests/chat/chat.js

# Server non-streaming chat completions
node tests/chat/server-non-stream.js

# Server streaming chat completions
node tests/chat/server-stream.js

# Chat tool calling with library
node tests/chat/tool-calling.js
```

### 🗣️ Responses API Tests

```bash
# Basic responses API via server
node tests/responses/server-responses.js

# Multi-turn conversation via server
node tests/responses/server-conversation-basic.js

# Conversation tool calling using library
node tests/responses/conversation-tool-calling.js

# Responses API tool calling via server
node tests/responses/server-tool-calling.js
```
</file>

<file path=".env.example">
PORT=3000
OPENAI_API_KEY=your_openai_api_key_here
GEMINI_API_KEY=your_gemini_api_key_here
OPENROUTER_API_KEY=your_openrouter_api_key_here
ZAI_API_KEY=your_zai_api_key_here
GROK_API_KEY=your_grok_api_key_here
QROQ_API_KEY=your_groq_api_key_here
GROQ_API_KEY=your_groq_api_key_here
CEREBRAS_API_KEY=your_cerebras_api_key_here
LLM7_API_KEY=your_llm7_api_key_here
</file>

<file path="provider.js">
module.exports = [
	{
		name: "openrouter",
		apiKey: [
			process.env.OPENROUTER_API_KEY,
			process.env.OPENROUTER_API_KEY_2,
			process.env.OPENROUTER_API_KEY_3,
			process.env.OPENROUTER_API_KEY_4,
			process.env.OPENROUTER_API_KEY_5,
			process.env.OPENROUTER_API_KEY_6,
			process.env.OPENROUTER_API_KEY_7,
			process.env.OPENROUTER_API_KEY_8,
			process.env.OPENROUTER_API_KEY_9,
			process.env.OPENROUTER_API_KEY_10,
			process.env.OPENROUTER_API_KEY_11,
			process.env.OPENROUTER_API_KEY_12,
			process.env.OPENROUTER_API_KEY_13,
			process.env.OPENROUTER_API_KEY_14,
			process.env.OPENROUTER_API_KEY_15,
			process.env.OPENROUTER_API_KEY_16,
			process.env.OPENROUTER_API_KEY_17,
			process.env.OPENROUTER_API_KEY_18,
			process.env.OPENROUTER_API_KEY_19,
			process.env.OPENROUTER_API_KEY_20,
			process.env.OPENROUTER_API_KEY_21,
			process.env.OPENROUTER_API_KEY_22,
			process.env.OPENROUTER_API_KEY_23,
			process.env.OPENROUTER_API_KEY_24,
			process.env.OPENROUTER_API_KEY_25,
			process.env.OPENROUTER_API_KEY_26,
			process.env.OPENROUTER_API_KEY_27
		],
		model: "xiaomi/mimo-v2-flash:free",
		apiUrl: "https://openrouter.ai/api/v1",
	},
	// {
	// 	name: "qroq",
	// 	apiKey: [
	// 		process.env.QROQ_API_KEY,
	// 		process.env.QROQ_API_KEY_2,
	// 		process.env.QROQ_API_KEY_3
	// 	],
	// 	model: "openai/gpt-oss-120b",
	// 	apiUrl: "https://api.groq.com/openai/v1",
	// },
	// {
	// 	name: "gemini_pro",
	// 	apiKey: [
	// 		process.env.GEMINI_API_KEY,
	// 		process.env.GEMINI_API_KEY_2,
	// 		process.env.GEMINI_API_KEY_3,
	// 		process.env.GEMINI_API_KEY_4,
	// 	],
	// 	model: "gemini-2.5-pro",
	// 	apiUrl: "https://generativelanguage.googleapis.com/v1beta/openai/",
	// },
	// {
	// 	name: "cerebras",
	// 	apiKey: [
	// 		process.env.CEREBRAS_API_KEY,
	// 		process.env.CEREBRAS_API_KEY_2,
	// 		process.env.CEREBRAS_API_KEY_3,
	// 	],
	// 	model: "gpt-oss-120b",
	// 	apiUrl: "https://api.cerebras.ai/v1",
	// },
	// {
	// 	name: "llm7",
	// 	apiKey: process.env.LLM7_API_KEY,
	// 	model: "deepseek-v3.1",
	// 	apiUrl: "https://api.llm7.io/v1",
	// },
	// {
	// 	name: "github",
	// 	apiKey: [
	// 		process.env.GITHUB_API_KEY_1,
	// 	],
	// 	model: "openai/gpt-4.1",
	// 	apiUrl: "https://models.github.ai/inference",
	// },
	// {
	// 	name: "gemini_flash",
	// 	apiKey: [
	// 		process.env.GEMINI_API_KEY,
	// 		process.env.GEMINI_API_KEY_2,
	// 		process.env.GEMINI_API_KEY_3,
	// 		process.env.GEMINI_API_KEY_4,
	// 	],
	// 	model: "gemini-2.5-flash",
	// 	apiUrl: "https://generativelanguage.googleapis.com/v1beta/openai/",
	// },
	// {
	// 	name: "z.ai",
	// 	apiKey: [
	// 		process.env.ZAI_API_KEY,
	// 		process.env.ZAI_API_KEY_2
	// 	],
	// 	model: "glm-4.5-flash",
	// 	apiUrl: "https://api.z.ai/api/paas/v4",
	// }
];
</file>

<file path="docs/deployment.md">
# 🚀 Deployment

Deploy Unified AI Router to various platforms.

## 🌈 Render.com

### 🖥️ Dashboard Method

1. **Push to GitHub first:**

   ```bash
   git push origin main
   ```

2. **Create Web Service on Render:**
   - Go to [dashboard.render.com](https://dashboard.render.com)
   - Click "New +" → "Web Service"
   - Connect your GitHub repository

3. **Configure Build Settings:**
   - **Build Command:** `npm install`
   - **Start Command:** `npm start`
   - **Node Version:** 24.x or higher

4. **Add Environment Variables:**

   ```bash
   OPENROUTER_API_KEY=your_key_here
   OPENAI_API_KEY=your_key_here
   PORT=3000
   ```

5. **Deploy and Test:**

   ```bash
   curl https://your-app.onrender.com/health
   curl https://your-app.onrender.com/models
   ```

### ✅ Verify Deployment

```bash
# Health check
curl https://your-app.onrender.com/health

# List available models
curl https://your-app.onrender.com/v1/models

# Test chat completions
curl -X POST https://your-app.onrender.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"messages":[{"role":"user","content":"Hello!"}],"model":"any"}'
```

## 🚄 Railway

1. **Install Railway CLI:**

   ```bash
   npm install -g @railway/cli
   ```

2. **Login and Initialize:**

   ```bash
   railway login
   railway init
   ```

3. **Set Environment Variables:**

   ```bash
   railway variables set OPENROUTER_API_KEY=your_key
   railway variables set OPENAI_API_KEY=your_key
   ```

4. **Deploy:**

   ```bash
   railway up
   ```

## ⚙️ Environment Configuration

### 🌍 Production .env

```bash
# Required API Keys
OPENROUTER_API_KEY=sk-or-your-key
OPENAI_API_KEY=sk-your-openai-key

# Server Configuration
PORT=3000
NODE_ENV=production

# Optional: Circuit Breaker Settings
CIRCUIT_TIMEOUT=30000
CIRCUIT_ERROR_THRESHOLD=50
CIRCUIT_RESET_TIMEOUT=300000
```

### 🔒 Security Considerations

1. **Never commit .env files to git**
2. **Use platform-specific environment variable management**
3. **Rotate API keys regularly**
4. **Monitor API usage and costs**
5. **Implement rate limiting if needed**

## 📊 Monitoring

### 🏥 Health Checks

```bash
# Basic health check
curl http://localhost:3000/health

# Provider status
curl http://localhost:3000/providers/status
```

### Logging

Logs include:

- Provider fallback events
- Circuit breaker state changes
- API response times
- Error details

View logs:

```bash
# Render
tail -f /var/log/app.log

# Heroku
heroku logs --tail

# Docker
docker logs -f container-name
```

## ⚡ Performance Tips

1. **Use multiple API keys** for load balancing
2. **Configure appropriate timeouts** based on provider speeds
3. **Monitor circuit breaker settings** to avoid premature failures
4. **Use streaming** for better user experience with long responses
5. **Cache responses** where appropriate
</file>

<file path="docs/sdk-usage.md">
# 📚 SDK Usage

Use the AIRouter library directly in your Node.js applications.

## 📦 Installation

```bash
npm install unified-ai-router
```

## ⚙️ Basic Setup

```javascript
const AIRouter = require("unified-ai-router");
require("dotenv").config();

const providers = [
  {
    name: "openai",
    apiKey: process.env.OPENAI_API_KEY,
    model: "gpt-4",
    apiUrl: "https://api.openai.com/v1"
  },
  {
    name: "openrouter", 
    apiKey: process.env.OPENROUTER_API_KEY,
    model: "mistralai/devstral-2512:free",
    apiUrl: "https://openrouter.ai/api/v1"
  }
];

const llm = new AIRouter(providers);
```

## 💬 Chat Completions

### Basic Usage

```javascript
const messages = [
  { role: "system", content: "You are a helpful coding assistant." },
  { role: "user", "Write a function to reverse a string in JavaScript." }
];

const response = await llm.chatCompletion(messages, {
  temperature: 0.7,
  max_tokens: 500
});

console.log(response.content);
```

### 🌊 Streaming

```javascript
const stream = await llm.chatCompletion(messages, {
  temperature: 0.7,
  stream: true  // Enable streaming
});

for await (const chunk of stream) {
  if (chunk.content) {
    process.stdout.write(chunk.content);
  }
}
```

### 🛠️ Tool Calling

```javascript
const tools = [
  {
    type: "function",
    function: {
      name: "get_weather",
      description: "Get current weather for a location",
      parameters: {
        type: "object",
        properties: {
          location: { type: "string", description: "City name" }
        }
      }
    }
  }
];

const response = await llm.chatCompletion(messages, {
  tools: tools,
  tool_choice: "auto"
});

console.log(response.tool_calls);
```

## 🗣️ Responses API

### Basic Usage

```javascript
const response = await llm.responses(
  "Tell me about artificial intelligence.",
  {
    temperature: 0.7,
    max_tokens: 500
  }
);

console.log(response.output_text);
```

### 🌊 Streaming

```javascript
const stream = await llm.responses(
  "Write a poem about coding.",
  {
    stream: true
  }
);

for await (const chunk of stream) {
  if (chunk.type === 'response.output_text.delta') {
    process.stdout.write(chunk.delta);
  }
}
```

### 🔄 Multi-turn Conversations

```javascript
// Initialize conversation
let input = [
  { role: "user", content: "I need help with JavaScript." }
];

let response = await llm.responses(input);
console.log(response.output_text);

// Continue conversation with context
input.push(
  { role: "user", content: "Can you show me a closure example?" }
);

response = await llm.responses(input);
console.log(response.output_text);
```

## 🔀 Load Balancing

```javascript
const providers = [
  {
    name: "openai",
    apiKey: [  // Array of API keys
      process.env.OPENAI_API_KEY_1,
      process.env.OPENAI_API_KEY_2,
      process.env.OPENAI_API_KEY_3
    ],
    model: "gpt-4",
    apiUrl: "https://api.openai.com/v1"
  }
];
```
</file>

<file path="chatbot/chatbot.html">
<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>AI Chatbot</title>

	<!-- Favicons -->
	<link rel="icon" type="image/png" sizes="32x32" href="favicons/favicon-16x16.png">
	<link rel="apple-touch-icon" sizes="180x180" href="favicons/apple-touch-icon.png">
	<link rel="icon" type="image/x-icon" href="favicons/favicon.ico">

	<style>
		* {
			margin: 0;
			padding: 0;
			box-sizing: border-box;
		}

		:root {
			--bg-primary: #ffffff;
			--bg-secondary: #f8f9fa;
			--text-primary: #1a1a1a;
			--text-secondary: #6c757d;
			--border-color: #e9ecef;
			--user-msg-bg: #007bff;
			--user-msg-text: #ffffff;
			--ai-msg-bg: #f8f9fa;
			--ai-msg-text: #1a1a1a;
			--input-bg: #ffffff;
			--shadow: 0 2px 8px rgba(0, 0, 0, 0.08);
			--shadow-hover: 0 4px 12px rgba(0, 0, 0, 0.12);
		}

		.dark-mode {
			--bg-primary: #1a1a1a;
			--bg-secondary: #2d2d2d;
			--text-primary: #e9ecef;
			--text-secondary: #adb5bd;
			--border-color: #3d3d3d;
			--user-msg-bg: #0d6efd;
			--user-msg-text: #ffffff;
			--ai-msg-bg: #2d2d2d;
			--ai-msg-text: #e9ecef;
			--input-bg: #2d2d2d;
			--shadow: 0 2px 8px rgba(0, 0, 0, 0.3);
			--shadow-hover: 0 4px 12px rgba(0, 0, 0, 0.4);
		}

		body {
			font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', 'Helvetica Neue', Arial, sans-serif;
			background: var(--bg-primary);
			color: var(--text-primary);
			height: 100vh;
			overflow: hidden;
			transition: background 0.3s ease, color 0.3s ease;
		}

		/* Layout */
		.app-container {
			display: flex;
			height: 100vh;
		}

		/* Sidebar */
		.sidebar {
			width: 280px;
			background: var(--bg-secondary);
			border-right: 1px solid var(--border-color);
			display: flex;
			flex-direction: column;
			transition: transform 0.3s ease;
		}

		.sidebar-header {
			padding: 1rem 1.25rem;
			border-bottom: 1px solid var(--border-color);
		}

		.sidebar-header h2 {
			font-size: 1rem;
			font-weight: 600;
			margin-bottom: 0.75rem;
		}

		.new-chat-btn {
			width: 100%;
			padding: 0.625rem;
			background: var(--user-msg-bg);
			color: var(--user-msg-text);
			border: none;
			border-radius: 8px;
			font-size: 0.875rem;
			font-weight: 500;
			cursor: pointer;
			transition: opacity 0.2s ease;
		}

		.new-chat-btn:hover {
			opacity: 0.9;
		}

		.conversations-list {
			flex: 1;
			overflow-y: auto;
			padding: 0.5rem;
		}

		.conversations-list::-webkit-scrollbar {
			width: 6px;
		}

		.conversations-list::-webkit-scrollbar-track {
			background: transparent;
		}

		.conversations-list::-webkit-scrollbar-thumb {
			background: var(--border-color);
			border-radius: 3px;
		}

		.conversation-item {
			display: flex;
			align-items: center;
			gap: 0.5rem;
			padding: 0.75rem;
			margin-bottom: 0.25rem;
			border-radius: 8px;
			cursor: pointer;
			transition: background 0.2s ease;
		}

		.conversation-item:hover {
			background: var(--bg-primary);
		}

		.conversation-item.active {
			background: var(--bg-primary);
			font-weight: 500;
		}

		.conversation-title {
			flex: 1;
			font-size: 0.875rem;
			white-space: nowrap;
			overflow: hidden;
			text-overflow: ellipsis;
		}

		.delete-btn {
			opacity: 0;
			padding: 0.25rem 0.5rem;
			background: transparent;
			border: none;
			color: var(--text-secondary);
			cursor: pointer;
			border-radius: 4px;
			transition: all 0.2s ease;
			font-size: 0.875rem;
		}

		.conversation-item:hover .delete-btn {
			opacity: 1;
		}

		.delete-btn:hover {
			background: rgba(220, 53, 69, 0.1);
			color: #dc3545;
		}

		.sidebar-footer {
			padding: 1rem 1.25rem;
			border-top: 1px solid var(--border-color);
		}

		.sidebar-footer .btn {
			width: 100%;
			padding: 0.625rem;
			margin-bottom: 0.5rem;
			background: transparent;
			border: none;
			border-radius: 8px;
			cursor: pointer;
			transition: background 0.2s ease;
			color: var(--text-primary);
			font-size: 0.875rem;
		}

		.sidebar-footer .btn:hover {
			background: var(--bg-primary);
		}

		.container {
			display: flex;
			flex-direction: column;
			flex: 1;
			height: 100vh;
		}

		/* Mobile sidebar toggle */
		.sidebar-toggle {
			display: none;
			position: fixed;
			top: 1rem;
			left: 1rem;
			z-index: 100;
			width: 40px;
			height: 40px;
			background: var(--bg-secondary);
			border: 1px solid var(--border-color);
			border-radius: 8px;
			cursor: pointer;
			align-items: center;
			justify-content: center;
		}

		.sidebar-overlay {
			display: none;
			position: fixed;
			top: 0;
			left: 0;
			width: 100%;
			height: 100%;
			background: rgba(0, 0, 0, 0.5);
			z-index: 999;
		}

		@media (max-width: 768px) {
			.sidebar {
				position: fixed;
				left: 0;
				top: 0;
				height: 100vh;
				z-index: 1000;
				transform: translateX(-100%);
			}

			.sidebar.open {
				transform: translateX(0);
			}

			.sidebar-overlay.active {
				display: block;
			}

			.sidebar-toggle {
				display: flex;
			}
		}

		/* Header */
		.header {
			display: flex;
			align-items: center;
			justify-content: space-between;
			padding: 1rem 1.5rem;
			border-bottom: 1px solid var(--border-color);
			background: var(--bg-primary);
		}

		.header h1 {
			font-size: 1.25rem;
			font-weight: 600;
			color: var(--text-primary);
		}

		.header-actions {
			display: flex;
			gap: 0.5rem;
		}

		.btn {
			padding: 0.5rem 1rem;
			border: none;
			border-radius: 8px;
			font-size: 0.875rem;
			font-weight: 500;
			cursor: pointer;
			transition: all 0.2s ease;
			background: transparent;
			color: var(--text-secondary);
		}

		.btn:hover {
			background: var(--bg-secondary);
			color: var(--text-primary);
		}

		.btn-primary {
			background: var(--user-msg-bg);
			color: var(--user-msg-text);
		}

		.btn-primary:hover {
			opacity: 0.9;
		}

		.icon-btn {
			width: 40px;
			height: 40px;
			padding: 0;
			display: flex;
			align-items: center;
			justify-content: center;
			border-radius: 50%;
		}

		/* Chat Area */
		.chat-area {
			flex: 1;
			overflow-y: auto;
			padding: 2rem 1.5rem;
			scroll-behavior: smooth;
		}

		.chat-area::-webkit-scrollbar {
			width: 6px;
		}

		.chat-area::-webkit-scrollbar-track {
			background: transparent;
		}

		.chat-area::-webkit-scrollbar-thumb {
			background: var(--border-color);
			border-radius: 3px;
		}

		.chat-area::-webkit-scrollbar-thumb:hover {
			background: var(--text-secondary);
		}

		/* Welcome Screen */
		.welcome {
			display: flex;
			flex-direction: column;
			align-items: center;
			justify-content: center;
			height: 100%;
			text-align: center;
			padding: 2rem;
		}

		.welcome-icon {
			width: 64px;
			height: 64px;
			background: var(--bg-secondary);
			border-radius: 16px;
			display: flex;
			align-items: center;
			justify-content: center;
			margin-bottom: 1.5rem;
		}

		.welcome h2 {
			font-size: 1.75rem;
			font-weight: 600;
			margin-bottom: 0.5rem;
		}

		.welcome p {
			color: var(--text-secondary);
			margin-bottom: 2rem;
			max-width: 500px;
		}

		/* Messages */
		.messages {
			display: flex;
			flex-direction: column;
			gap: 1.5rem;
		}

		.message {
			display: flex;
			gap: 1rem;
			animation: fadeIn 0.3s ease;
		}

		@keyframes fadeIn {
			from {
				opacity: 0;
				transform: translateY(10px);
			}

			to {
				opacity: 1;
				transform: translateY(0);
			}
		}

		.message.user {
			flex-direction: row-reverse;
		}

		.message-avatar {
			width: 36px;
			height: 36px;
			border-radius: 50%;
			display: flex;
			align-items: center;
			justify-content: center;
			flex-shrink: 0;
			font-size: 0.875rem;
			font-weight: 600;
		}

		.message.user .message-avatar {
			background: var(--user-msg-bg);
			color: var(--user-msg-text);
		}

		.message.assistant .message-avatar {
			background: var(--bg-secondary);
			color: var(--text-primary);
		}

		.message-content {
			flex: 1;
			max-width: 75%;
		}

		.message-bubble {
			padding: 1rem 1.25rem;
			border-radius: 16px;
			line-height: 1.6;
			word-wrap: break-word;
		}

		.message.user .message-bubble {
			background: var(--user-msg-bg);
			color: var(--user-msg-text);
			border-bottom-right-radius: 4px;
		}

		.message.assistant .message-bubble {
			background: var(--ai-msg-bg);
			color: var(--ai-msg-text);
			border-bottom-left-radius: 4px;
			box-shadow: var(--shadow);
		}

		/* Typing Indicator */
		.typing-indicator {
			display: flex;
			gap: 4px;
			padding: 1rem 1.25rem;
		}

		.typing-dot {
			width: 8px;
			height: 8px;
			border-radius: 50%;
			background: var(--text-secondary);
			animation: typing 1.4s infinite;
		}

		.typing-dot:nth-child(2) {
			animation-delay: 0.2s;
		}

		.typing-dot:nth-child(3) {
			animation-delay: 0.4s;
		}

		@keyframes typing {

			0%,
			60%,
			100% {
				opacity: 0.3;
				transform: scale(0.8);
			}

			30% {
				opacity: 1;
				transform: scale(1);
			}
		}

		/* Input Area */
		.input-area {
			padding: 1rem 1.5rem 1.5rem;
			border-top: 1px solid var(--border-color);
			background: var(--bg-primary);
		}

		.input-container {
			display: flex;
			gap: 0.75rem;
			align-items: flex-end;
			background: var(--input-bg);
			border: 1px solid var(--border-color);
			border-radius: 12px;
			padding: 1rem;
			box-shadow: var(--shadow);
			transition: box-shadow 0.2s ease;
		}

		.input-container:focus-within {
			box-shadow: var(--shadow-hover);
		}

		.input-container textarea {
			flex: 1;
			border: none;
			outline: none;
			background: transparent;
			color: var(--text-primary);
			font-family: inherit;
			font-size: 1rem;
			resize: none;
			max-height: 200px;
			line-height: 1.6;
			min-height: 48px;
		}

		.input-container textarea::placeholder {
			color: var(--text-secondary);
		}

		.send-btn {
			width: 40px;
			height: 40px;
			border-radius: 8px;
			background: var(--user-msg-bg);
			color: var(--user-msg-text);
			border: none;
			cursor: pointer;
			display: flex;
			align-items: center;
			justify-content: center;
			transition: opacity 0.2s ease;
			flex-shrink: 0;
		}

		.send-btn:disabled {
			opacity: 0.4;
			cursor: not-allowed;
		}

		.send-btn:not(:disabled):hover {
			opacity: 0.9;
		}

		.input-hint {
			text-align: center;
			margin-top: 0.75rem;
			font-size: 0.75rem;
			color: var(--text-secondary);
		}

		/* Markdown Styles */
		.markdown-content p {
			margin: 0.5rem 0;
		}

		.markdown-content p:first-child {
			margin-top: 0;
		}

		.markdown-content p:last-child {
			margin-bottom: 0;
		}

		.markdown-content code {
			background: var(--bg-secondary);
			padding: 0.125rem 0.375rem;
			border-radius: 4px;
			font-size: 0.875em;
			font-family: 'Courier New', monospace;
		}

		.markdown-content pre {
			background: var(--bg-secondary);
			padding: 1rem;
			border-radius: 8px;
			overflow-x: auto;
			margin: 0.75rem 0;
		}

		.markdown-content pre code {
			background: transparent;
			padding: 0;
		}

		.markdown-content ul,
		.markdown-content ol {
			margin: 0.5rem 0;
			padding-left: 1.5rem;
		}

		.markdown-content li {
			margin: 0.25rem 0;
		}

		.markdown-content h1,
		.markdown-content h2,
		.markdown-content h3 {
			margin: 1rem 0 0.5rem;
			font-weight: 600;
		}

		.markdown-content h1 {
			font-size: 1.5rem;
		}

		.markdown-content h2 {
			font-size: 1.25rem;
		}

		.markdown-content h3 {
			font-size: 1.125rem;
		}

		/* Settings Modal */
		.modal {
			display: none;
			position: fixed;
			top: 0;
			left: 0;
			width: 100%;
			height: 100%;
			background: rgba(0, 0, 0, 0.5);
			z-index: 2000;
			align-items: center;
			justify-content: center;
		}

		.modal.active {
			display: flex;
		}

		.modal-content {
			background: var(--bg-primary);
			border-radius: 16px;
			padding: 2rem;
			max-width: 500px;
			width: 90%;
			box-shadow: 0 8px 32px rgba(0, 0, 0, 0.2);
		}

		.modal-header {
			display: flex;
			justify-content: space-between;
			align-items: center;
			margin-bottom: 1.5rem;
		}

		.modal-header h3 {
			font-size: 1.25rem;
			font-weight: 600;
		}

		.modal-body {
			margin-bottom: 1.5rem;
		}

		.form-group {
			margin-bottom: 1.5rem;
		}

		.form-group label {
			display: block;
			margin-bottom: 0.5rem;
			font-weight: 500;
			font-size: 0.875rem;
		}

		.form-group select,
		.form-group input {
			width: 100%;
			padding: 0.75rem;
			border: 1px solid var(--border-color);
			border-radius: 8px;
			background: var(--input-bg);
			color: var(--text-primary);
			font-family: inherit;
			font-size: 0.9375rem;
		}

		.form-group input[type="range"] {
			padding: 0;
		}

		.range-value {
			display: block;
			margin-top: 0.5rem;
			font-size: 0.875rem;
			color: var(--text-secondary);
		}

		.modal-footer {
			display: flex;
			gap: 0.75rem;
			justify-content: flex-end;
		}

		/* Responsive */
		@media (max-width: 768px) {
			.header {
				padding: 1rem;
			}

			.chat-area {
				padding: 1.5rem 1rem;
			}

			.input-area {
				padding: 1rem;
			}

			.message-content {
				max-width: 85%;
			}

			.welcome h2 {
				font-size: 1.5rem;
			}
		}

		/* Utility */
		.hidden {
			display: none !important;
		}
	</style>
</head>

<body>
	<div class="app-container">
		<!-- Sidebar -->
		<aside class="sidebar" id="sidebar">
			<div class="sidebar-header">
				<h2>AI Chatbot</h2>
				<button class="new-chat-btn" onclick="createNewChat()">+ New Chat</button>
			</div>
			<div class="conversations-list" id="conversationsList">
				<!-- Conversations will be rendered here -->
			</div>
			<div class="sidebar-footer">
				<button class="btn" onclick="toggleTheme()">
					<span>🌓</span> Toggle Theme
				</button>
				<button class="btn" onclick="showSettings()">
					<span>⚙️</span> Settings
				</button>
			</div>
		</aside>

		<!-- Sidebar Overlay (Mobile) -->
		<div class="sidebar-overlay" id="sidebarOverlay" onclick="toggleSidebar()"></div>

		<!-- Sidebar Toggle (Mobile) -->
		<button class="sidebar-toggle" id="sidebarToggle" onclick="toggleSidebar()">
			<svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
				<line x1="3" y1="12" x2="21" y2="12"></line>
				<line x1="3" y1="6" x2="21" y2="6"></line>
				<line x1="3" y1="18" x2="21" y2="18"></line>
			</svg>
		</button>

		<!-- Main Container -->
		<div class="container">
			<!-- Header -->
			<header class="header">
				<h1 id="chatTitle">AI Chatbot</h1>
				<div class="header-actions">
					<button class="btn" onclick="clearCurrentChat()">Clear</button>
				</div>
			</header>

			<!-- Chat Area -->
			<div class="chat-area" id="chatArea">
				<!-- Welcome Screen -->
				<div class="welcome" id="welcomeScreen">
					<div class="welcome-icon">
						<svg width="32" height="32" viewBox="0 0 32 32" fill="currentColor">
							<path
								d="M16 26C13.826 26 11.712 25.291 9.977 23.98C8.242 22.67 6.981 20.83 6.386 18.739C5.791 16.648 5.893 14.42 6.678 12.392C7.463 10.365 8.887 8.648 10.735 7.503C12.583 6.358 14.754 5.846 16.919 6.045C19.084 6.245 21.125 7.144 22.732 8.608C24.34 10.072 25.427 12.019 25.828 14.156C26.229 16.293 25.923 18.502 24.956 20.449L25.421 23.832L21.603 24.822C20.217 25.645 18.622 26.006 17 26H16Z" />
						</svg>
					</div>
					<h2>Welcome to AI Chatbot</h2>
					<p>Start a conversation and experience the power of AI. Ask me anything!</p>
				</div>

				<!-- Messages Container -->
				<div class="messages hidden" id="messagesContainer"></div>
			</div>

			<!-- Input Area -->
			<div class="input-area">
				<div class="input-container">
					<textarea id="messageInput" placeholder="Type your message..." rows="1" onkeydown="handleKeyPress(event)"
						oninput="handleInput()"></textarea>
					<button class="send-btn" id="sendBtn" onclick="sendMessage()" disabled>
						<svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
							<line x1="22" y1="2" x2="11" y2="13"></line>
							<polygon points="22 2 15 22 11 13 2 9 22 2"></polygon>
						</svg>
					</button>
				</div>
				<div class="input-hint">AI may produce inaccurate information</div>
			</div>
		</div>
	</div>

	<!-- Settings Modal -->
	<div class="modal" id="settingsModal" onclick="closeModalOnBackdrop(event)">
		<div class="modal-content">
			<div class="modal-header">
				<h3>Settings</h3>
				<button class="btn icon-btn" onclick="closeSettings()">
					<svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
						<line x1="18" y1="6" x2="6" y2="18"></line>
						<line x1="6" y1="6" x2="18" y2="18"></line>
					</svg>
				</button>
			</div>
			<div class="modal-body">
				<div class="form-group">
					<label for="modelSelect">Model</label>
					<select id="modelSelect">
						<option value="">Auto-select (Recommended)</option>
					</select>
				</div>
				<div class="form-group">
					<label for="temperatureSlider">Temperature</label>
					<input type="range" id="temperatureSlider" min="0" max="2" step="0.1" value="0.7"
						oninput="updateTemperatureValue()">
					<span class="range-value">Value: <span id="temperatureValue">0.7</span></span>
				</div>
			</div>
			<div class="modal-footer">
				<button class="btn" onclick="closeSettings()">Cancel</button>
				<button class="btn btn-primary" onclick="saveSettings()">Save</button>
			</div>
		</div>
	</div>

	<!-- Marked.js for Markdown -->
	<script src="marked.umd.js"></script>

	<script>
		// State
		let conversations = JSON.parse(localStorage.getItem('chatbot-conversations') || '[]');
		let currentConversationId = null;
		let isTyping = false;
		const API_BASE = window.location.origin;

		// Theme Management
		function toggleTheme() {
			document.body.classList.toggle('dark-mode');
			const isDark = document.body.classList.contains('dark-mode');
			localStorage.setItem('theme', isDark ? 'dark' : 'light');
		}

		// Initialize theme
		const savedTheme = localStorage.getItem('theme');
		if (savedTheme === 'dark' || (!savedTheme && window.matchMedia('(prefers-color-scheme: dark)').matches)) {
			document.body.classList.add('dark-mode');
		}

		// Sidebar Management
		function toggleSidebar() {
			const sidebar = document.getElementById('sidebar');
			const overlay = document.getElementById('sidebarOverlay');
			sidebar.classList.toggle('open');
			overlay.classList.toggle('active');
		}

		// Conversation Management
		function createNewChat() {
			const newConv = {
				id: Date.now(),
				title: 'New Chat',
				messages: [],
				created: new Date().toISOString()
			};
			conversations.unshift(newConv);
			saveConversations();
			loadConversation(newConv.id);
			renderConversationsList();
		}

		function loadConversation(id) {
			currentConversationId = id;
			const conv = conversations.find(c => c.id === id);
			if (!conv) return;

			renderMessages(conv.messages);
			renderConversationsList();
			document.getElementById('chatTitle').textContent = conv.title;

			// Close sidebar on mobile
			if (window.innerWidth <= 768) {
				toggleSidebar();
			}
		}

		function deleteConversation(id, event) {
			event.stopPropagation();
			if (!confirm('Delete this conversation?')) return;

			conversations = conversations.filter(c => c.id !== id);
			saveConversations();

			if (currentConversationId === id) {
				if (conversations.length > 0) {
					loadConversation(conversations[0].id);
				} else {
					currentConversationId = null;
					renderMessages([]);
					document.getElementById('chatTitle').textContent = 'AI Chatbot';
				}
			}

			renderConversationsList();
		}

		function saveConversations() {
			localStorage.setItem('chatbot-conversations', JSON.stringify(conversations));
		}

		function renderConversationsList() {
			const container = document.getElementById('conversationsList');

			if (conversations.length === 0) {
				container.innerHTML = '<div style="padding: 1rem; text-align: center; color: var(--text-secondary); font-size: 0.875rem;">No conversations yet</div>';
				return;
			}

			container.innerHTML = conversations.map(conv => `
				<div class="conversation-item ${currentConversationId === conv.id ? 'active' : ''}" onclick="loadConversation(${conv.id})">
					<div class="conversation-title">${escapeHtml(conv.title)}</div>
					<button class="delete-btn" onclick="deleteConversation(${conv.id}, event)">×</button>
				</div>
			`).join('');
		}

		function clearCurrentChat() {
			if (!currentConversationId) return;
			if (!confirm('Clear all messages in this chat?')) return;

			const conv = conversations.find(c => c.id === currentConversationId);
			if (conv) {
				conv.messages = [];
				conv.title = 'New Chat';
				saveConversations();
				renderMessages([]);
				renderConversationsList();
				document.getElementById('chatTitle').textContent = 'New Chat';
			}
		}

		// Input handling
		function handleInput() {
			const input = document.getElementById('messageInput');
			const sendBtn = document.getElementById('sendBtn');

			// Auto-resize textarea
			input.style.height = 'auto';
			input.style.height = input.scrollHeight + 'px';

			// Enable/disable send button
			sendBtn.disabled = !input.value.trim() || isTyping;
		}

		function handleKeyPress(event) {
			if (event.key === 'Enter' && !event.shiftKey) {
				event.preventDefault();
				sendMessage();
			}
		}

		// Message handling
		async function sendMessage() {
			const input = document.getElementById('messageInput');
			const text = input.value.trim();

			if (!text || isTyping) return;

			// Create new conversation if none exists
			if (!currentConversationId) {
				createNewChat();
			}

			const conv = conversations.find(c => c.id === currentConversationId);
			if (!conv) return;

			// Add user message
			conv.messages.push({ role: 'user', content: text, timestamp: Date.now() });

			// Update conversation title from first message
			if (conv.messages.filter(m => m.role === 'user').length === 1) {
				conv.title = text.substring(0, 50) + (text.length > 50 ? '...' : '');
				document.getElementById('chatTitle').textContent = conv.title;
			}

			saveConversations();
			renderMessages(conv.messages);
			renderConversationsList();

			// Clear input
			input.value = '';
			input.style.height = 'auto';
			handleInput();

			// Show typing indicator
			showTypingIndicator();

			try {
				const response = await fetch(`${API_BASE}/v1/chat/completions`, {
					method: 'POST',
					headers: { 'Content-Type': 'application/json' },
					body: JSON.stringify({
						messages: conv.messages.map(m => ({ role: m.role, content: m.content })),
						model: document.getElementById('modelSelect').value || undefined,
						temperature: parseFloat(document.getElementById('temperatureSlider').value),
						stream: false
					})
				});

				if (!response.ok) {
					throw new Error(`HTTP error! status: ${response.status}`);
				}

				const data = await response.json();
				const assistantMessage = data.choices[0]?.message?.content || 'Sorry, I couldn\'t generate a response.';

				hideTypingIndicator();

				// Add assistant message
				conv.messages.push({ role: 'assistant', content: assistantMessage, timestamp: Date.now() });
				saveConversations();
				renderMessages(conv.messages);

			} catch (error) {
				console.error('Error:', error);
				hideTypingIndicator();
				conv.messages.push({ role: 'assistant', content: `Error: ${error.message}`, timestamp: Date.now() });
				saveConversations();
				renderMessages(conv.messages);
			}
		}

		function renderMessages(messages) {
			const welcomeScreen = document.getElementById('welcomeScreen');
			const messagesContainer = document.getElementById('messagesContainer');

			if (messages.length === 0) {
				welcomeScreen.classList.remove('hidden');
				messagesContainer.classList.add('hidden');
				return;
			}

			welcomeScreen.classList.add('hidden');
			messagesContainer.classList.remove('hidden');

			messagesContainer.innerHTML = messages.map(msg => {
				const avatar = msg.role === 'user' ? 'U' : 'AI';
				const content = msg.role === 'assistant'
					? `<div class="markdown-content">${marked.parse(msg.content)}</div>`
					: escapeHtml(msg.content);

				return `
					<div class="message ${msg.role}">
						<div class="message-avatar">${avatar}</div>
						<div class="message-content">
							<div class="message-bubble">${content}</div>
						</div>
					</div>
				`;
			}).join('');

			scrollToBottom();
		}

		function showTypingIndicator() {
			isTyping = true;
			const messagesContainer = document.getElementById('messagesContainer');

			const typingHtml = `
				<div class="message assistant" id="typingIndicator">
					<div class="message-avatar">AI</div>
					<div class="message-content">
						<div class="message-bubble">
							<div class="typing-indicator">
								<div class="typing-dot"></div>
								<div class="typing-dot"></div>
								<div class="typing-dot"></div>
							</div>
						</div>
					</div>
				</div>
			`;

			messagesContainer.insertAdjacentHTML('beforeend', typingHtml);
			scrollToBottom();
		}

		function hideTypingIndicator() {
			isTyping = false;
			const indicator = document.getElementById('typingIndicator');
			if (indicator) indicator.remove();
		}

		function scrollToBottom() {
			const chatArea = document.getElementById('chatArea');
			chatArea.scrollTop = chatArea.scrollHeight;
		}

		// Settings
		function showSettings() {
			document.getElementById('settingsModal').classList.add('active');
		}

		function closeSettings() {
			document.getElementById('settingsModal').classList.remove('active');
		}

		function closeModalOnBackdrop(event) {
			if (event.target.classList.contains('modal')) {
				closeSettings();
			}
		}

		function updateTemperatureValue() {
			const slider = document.getElementById('temperatureSlider');
			document.getElementById('temperatureValue').textContent = slider.value;
		}

		function saveSettings() {
			closeSettings();
		}

		// Utility
		function escapeHtml(text) {
			const div = document.createElement('div');
			div.textContent = text;
			return div.innerHTML;
		}

		// Configure marked
		marked.setOptions({
			breaks: true,
			gfm: true
		});

		// Initialize
		renderConversationsList();
		if (conversations.length > 0) {
			loadConversation(conversations[0].id);
		}
		document.getElementById('messageInput').focus();
	</script>
</body>

</html>
</file>

<file path="docs/configuration.md">
# Configuration

Set up environment variables and providers.

## Environment

Copy `.env.example` to `.env` and add your API keys:

```bash
cp .env.example .env
```

Common keys:

- `OPENAI_API_KEY` - OpenAI
- `OPENROUTER_API_KEY` - OpenRouter  
- `PORT` - Server port (default: 3000)

## Providers

Edit `provider.js` - it's an array of providers tried in order:

```js
module.exports = [
  {
    name: "openrouter",
    apiKey: process.env.OPENROUTER_API_KEY,
    model: "mistralai/devstral-2512:free",
    apiUrl: "https://openrouter.ai/api/v1"
  },
  {
    name: "openai", 
    apiKey: process.env.OPENAI_API_KEY,
    model: "gpt-4",
    apiUrl: "https://api.openai.com/v1"
  }
];
```

## Circuit Breakers

Built-in fault tolerance. Default settings:

- **timeout**: 300000ms (5 minutes)
- **errorThresholdPercentage**: 50%
- **resetTimeout**: 9000000ms (15 minutes)

Override per provider:

```js
{
  name: "openai",
  apiKey: process.env.OPENAI_API_KEY,
  model: "gpt-4",
  apiUrl: "https://api.openai.com/v1",
  circuitOptions: {
    timeout: 30000,
    errorThresholdPercentage: 50,
    resetTimeout: 300000
  }
}
```

## Multiple API Keys

```js
{
  name: "openrouter",
  apiKey: [process.env.OPENROUTER_API_KEY, process.env.OPENROUTER_API_KEY_2],
  model: "mistralai/devstral-2512:free",
  apiUrl: "https://openrouter.ai/api/v1"
}
```
</file>

<file path="openai-server.js">
const http = require( "http" );
const express = require( "express" );
const cors = require( "cors" );
const pino = require( "pino" );
const pretty = require( "pino-pretty" );
const pinoStream = pretty({ colorize: true, ignore: "pid,hostname" });
const logger = pino({ base: false }, pinoStream );
require( "dotenv" ).config({ quiet: true });
const AIRouter = require( "./main" );
const providers = require( "./provider" )
const aiRouter = new AIRouter( providers );

const app = express();
const path = require( "path" );
app.use( cors() );
app.use( express.json({ limit: "50mb" }) );


const handleResponses = async ( req, res ) =>
{
	const { input, model, stream, ...rest } = req.body;

	if ( !input )
	{
		return res.status( 400 ).json({ error: { message: "input is required" } });
	}

	if ( stream )
	{
		res.setHeader( "Content-Type", "text/event-stream" );
		res.setHeader( "Cache-Control", "no-cache" );
		res.setHeader( "Connection", "keep-alive" );

		try
		{
			const result = await aiRouter.responsesWithResponse( input, { model, stream, ...rest });

			for await ( const chunk of result.data )
			{
				res.write( `data: ${JSON.stringify( chunk )}\n\n` );
			}

			res.write( "data: [DONE]\n\n" );
		}
		catch ( err )
		{
			logger.error( err );
			res.write( `data: ${JSON.stringify({ error: { message: err.message } })}\n\n` );
			res.write( "data: [DONE]\n\n" );
		}
		res.end();
	}
	else
	{
		try
		{
			const result = await aiRouter.responsesWithResponse( input, { model, stream, ...rest });
			res.json( result.data );
		}
		catch ( err )
		{
			logger.error( err );
			res.status( 500 ).json({ error: { message: err.message } });
		}
	}
};

const handleChatCompletion = async ( req, res ) =>
{
	const { messages, model, stream, ...rest } = req.body;

	if ( !messages || !Array.isArray( messages ) )
	{
		return res.status( 400 ).json({ error: { message: "messages must be an array" } });
	}

	if ( stream )
	{
		res.setHeader( "Content-Type", "text/event-stream" );
		res.setHeader( "Cache-Control", "no-cache" );
		res.setHeader( "Connection", "keep-alive" );

		try
		{
			const result = await aiRouter.chatCompletionWithResponse( messages, { model, stream, ...rest });

			for await ( const chunk of result.data )
			{
				res.write( `data: ${JSON.stringify( chunk )}\n\n` );
			}

			res.write( "data: [DONE]\n\n" );
		}
		catch ( err )
		{
			logger.error( err );
			res.write( `data: ${JSON.stringify({ error: { message: err.message } })}\n\n` );
			res.write( "data: [DONE]\n\n" );
		}
		res.end();
	}
	else
	{
		try
		{
			const result = await aiRouter.chatCompletionWithResponse( messages, { model, stream, ...rest });
			res.json( result.data );
		}
		catch ( err )
		{
			logger.error( err );
			res.status( 500 ).json({ error: { message: err.message } });
		}
	}
};

const handleGetModels = async ( req, res ) =>
{
	try
	{
		const models = await aiRouter.getModels();
		res.json({ data: models });
	}
	catch ( error )
	{
		logger.error( `Error in /v1/models: ${error.message}` );
		res.status( 500 ).json({ error: { message: error.message } });
	}
};

app.post( "/v1/responses", handleResponses );
app.post( "/responses", handleResponses );

app.post( "/v1/chat/completions", handleChatCompletion );
app.post( "/chat/completions", handleChatCompletion );

app.get( "/v1/models", handleGetModels );
app.get( "/models", handleGetModels );

// Serve chatbot static files
app.use( express.static( path.join( __dirname, "chatbot" ) ) );

app.get( "/health", ( req, res ) => { return res.json({ status: "ok" }) });

app.get( "/", ( req, res ) =>
{
	res.sendFile( path.join( __dirname, "chatbot", "chatbot.html" ) );
});

app.get( "/providers/status", async ( req, res ) =>
{
	try
	{
		const statuses = await aiRouter.checkProvidersStatus();
		res.json({ data: statuses });
	}
	catch ( error )
	{
		logger.error( `Error in /providers/status: ${error.message}` );
		res.status( 500 ).json({ error: { message: error.message } });
	}
});

const PORT = process.env.PORT || 3000;
app.listen( PORT, ( e ) =>
{
	if ( e )
	{
		logger.error( `Failed to start server: ${e.message}` );
		process.exit( 1 );
	}
	else
	{
		logger.info( `🚀 OpenAI-compatible API listening at http://localhost:${PORT}/v1/chat/completions and /v1/responses` );
		logger.info( `🌐 Chatbot interface available at http://localhost:${PORT}/` );

		setTimeout( () =>
		{
			const url = `http://localhost:${PORT}/health`;
			http.get( url, ( res ) =>
			{
				if ( res.statusCode === 200 )
				{
					logger.info( "Keep-alive ping successful." );
				}
				else
				{
					logger.error( `Keep-alive ping failed with status code: ${res.statusCode}` );
				}
			}).on( "error", ( err ) =>
			{
				logger.error( "Error sending keep-alive ping:", err.message );
			});
		}, 14 * 60 * 1000 ); // 14 minutes
	}
});
</file>

<file path="main.js">
const OpenAI = require( "openai" );
const pino = require( "pino" );
const pretty = require( "pino-pretty" );
const CircuitBreaker = require( "opossum" );

const logger = pino({ base: false }, pretty({ colorize: true, ignore: "pid,hostname" }) );

class AIRouter
{
	constructor ( providers )
	{
		this.providers = this._initializeProviders( providers );
		this._setupCircuitBreakers();
	}

	_setupCircuitBreakers ()
	{
		const defaultCircuitOptions = {
			timeout: 300000,
			errorThresholdPercentage: 50,
			resetTimeout: 9000000
		};

		for ( const provider of this.providers )
		{
			// Chat Completions action
			const chatAction = async ({ params, withResponse }) =>
			{
				const client = this.createClient( provider );
				if ( withResponse )
				{
					return client.chat.completions.create( params ).withResponse();
				}
				return client.chat.completions.create( params );
			};

			// Responses API action
			const responsesAction = async ({ params, withResponse }) =>
			{
				const client = this.createClient( provider );
				if ( withResponse )
				{
					return client.responses.create( params ).withResponse();
				}
				return client.responses.create( params );
			};

			const action = async ({ params, withResponse, isResponses = false }) =>
			{
				if ( isResponses )
				{
					return responsesAction({ params, withResponse });
				}
				return chatAction({ params, withResponse });
			};

			const options = { ...defaultCircuitOptions, ...provider.circuitOptions };
			const breaker = new CircuitBreaker( action, options );

			// Expanded logging for readability
			breaker.on( "open", () =>
			{
				logger.info( `Circuit open for ${provider.name}` );
			});
			breaker.on( "halfOpen", () =>
			{
				logger.info( `Circuit half-open for ${provider.name}` );
			});
			breaker.on( "close", () =>
			{
				logger.info( `Circuit closed for ${provider.name}` );
			});
			breaker.on( "fallback", () =>
			{
				logger.warn( `Fallback triggered for ${provider.name}` );
			});
			breaker.on( "failure", ( err ) =>
			{
				logger.error({ provider: provider.name, error: err.message, metadata: err?.error?.metadata }, "Breaker failure" );
			});

			breaker.fallback( () =>
			{
				this._reorderProvidersOnFailure( provider );
				throw new Error( `Circuit open for ${provider.name}` );
			});

			provider.breaker = breaker;
		}
	}

	/**
	 * Reorder providers by moving a failed provider to the end of the list
	 * @param {Object} failedProvider - The provider that failed
	 */
	_reorderProvidersOnFailure ( failedProvider )
	{
		const currentIndex = this.providers.indexOf( failedProvider );
		if ( currentIndex !== -1 && currentIndex !== this.providers.length - 1 )
		{
			// Remove from current position and add to end
			this.providers.splice( currentIndex, 1 );
			this.providers.push( failedProvider );
			logger.info( `Moved failed provider ${failedProvider.name} to end of list` );
		}
	}

	createClient ( provider )
	{
		return new OpenAI({
			apiKey: provider.apiKey,
			baseURL: provider.apiUrl,
			timeout: 60000
		});
	}

	async responses ( input, options = {})
	{
		const { stream, tools, ...restOptions } = options;
		const isStreaming = stream;

		// Create a snapshot of providers to avoid issues with array modification during iteration
		const providersSnapshot = [...this.providers];

		for ( const provider of providersSnapshot )
		{
			try
			{
				const params = {
					input,
					...restOptions,
					model: provider.model,
					stream: isStreaming
				};

				if ( tools && tools.length > 0 )
				{
					params.tools = tools;
				}

				const result = await provider.breaker.fire({ params, withResponse: false, isResponses: true });

				if ( isStreaming )
				{
					return ( async function* ()
					{
						for await ( const chunk of result )
						{
							yield chunk;
						}
					})();
				}

				return result;
			}
			catch ( error )
			{
				logger.error( `Failed with ${provider.name}: ${error.message}` );
			}
		}
		throw new Error( "All providers failed" );
	}

	async responsesWithResponse ( input, options = {})
	{
		const { stream, tools, ...restOptions } = options;
		const isStreaming = stream;

		// Create a snapshot of providers to avoid issues with array modification during iteration
		const providersSnapshot = [...this.providers];

		for ( const provider of providersSnapshot )
		{
			try
			{
				const params = {
					input,
					...restOptions,
					model: provider.model,
					stream: isStreaming
				};

				if ( tools && tools.length > 0 )
				{
					params.tools = tools;
				}

				return await provider.breaker.fire({ params, withResponse: true, isResponses: true });
			}
			catch ( error )
			{
				logger.error( `Failed with ${provider.name}: ${error.message}` );
			}
		}
		throw new Error( "All providers failed" );
	}

	async chatCompletion ( messages, options = {})
	{
		const { stream, tools, ...restOptions } = options;
		const isStreaming = stream;

		// Create a snapshot of providers to avoid issues with array modification during iteration
		const providersSnapshot = [...this.providers];

		for ( const provider of providersSnapshot )
		{
			try
			{
				const params = {
					messages,
					...restOptions,
					model: provider.model,
					stream: isStreaming
				};

				if ( tools && tools.length > 0 )
				{
					params.tools = tools;
				}

				const result = await provider.breaker.fire({ params, withResponse: false });

				if ( isStreaming )
				{
					return ( async function* ()
					{
						for await ( const chunk of result )
						{
							try
							{
								const delta = chunk.choices[0]?.delta;
								if ( delta )
								{
									if ( delta.content !== null && delta.content !== undefined )
									{
										chunk.content = delta.content;
									}
									if ( delta.reasoning !== null && delta.reasoning !== undefined )
									{
										chunk.reasoning = delta.reasoning;
									}
									if ( delta.tool_calls !== null && delta.tool_calls !== undefined )
									{
										chunk.tool_calls_delta = delta.tool_calls;
									}
								}
								yield chunk;
							}
							catch ( error )
							{
								console.log( error );
							}
						}
					})();
				}

				// Non-streaming response handling
				const response = result;
				const message = response.choices[0]?.message;

				if ( message )
				{
					if ( message.content !== null ) response.content = message.content;
					if ( message.reasoning !== null ) response.reasoning = message.reasoning;
					if ( message.tool_calls !== null ) response.tool_calls = message.tool_calls;
				}

				return response;
			}
			catch ( error )
			{
				logger.error( `Failed with ${provider.name}: ${error.message}` );
			}
		}
		throw new Error( "All providers failed" );
	}

	async chatCompletionWithResponse ( messages, options = {})
	{
		const { stream, tools, ...restOptions } = options;
		const isStreaming = stream;

		// Create a snapshot of providers to avoid issues with array modification during iteration
		const providersSnapshot = [...this.providers];

		for ( const provider of providersSnapshot )
		{
			try
			{
				const params = {
					messages,
					...restOptions,
					model: provider.model,
					stream: isStreaming
				};

				if ( tools && tools.length > 0 )
				{
					params.tools = tools;
				}

				return await provider.breaker.fire({ params, withResponse: true });
			}
			catch ( error )
			{
				logger.error( `Failed with ${provider.name}: ${error.message}` );
			}
		}
		throw new Error( "All providers failed" );
	}

	async getModels ()
	{
		const models = [];
		// Create a snapshot of providers to avoid issues with array modification during iteration
		const providersSnapshot = [...this.providers];

		for ( const provider of providersSnapshot )
		{
			try
			{
				const client = this.createClient( provider );
				const listResponse = await client.models.list();

				// Handle different API response structures
				const modelList = Array.isArray( listResponse.data )
					? listResponse.data
					: listResponse.body || [];

				const model = modelList.find( m =>
				{
					return m.id === provider.model || m.id === `models/${provider.model}`;
				});

				if ( model )
				{
					models.push( model );
				}
				else
				{
					logger.warn( `Model ${provider.model} not found in provider ${provider.name}` );
				}
			}
			catch ( error )
			{
				logger.error( `Failed to list models for ${provider.name}: ${error.message}` );
			}
		}
		return models;
	}

	async checkProvidersStatus ()
	{
		const maskApiKey = ( key ) =>
		{
			if ( key && key.length >= 8 )
			{
				return `${key.substring( 0, 4 )}...${key.substring( key.length - 4 )}`;
			}
			return "Invalid API Key";
		};

		const promises = this.providers.map( async ( provider ) =>
		{
			try
			{
				const client = this.createClient( provider );
				await client.chat.completions.create({
					messages: [{ role: "user", content: "test" }],
					model: provider.model,
					max_tokens: 1
				});

				return {
					name: provider.name,
					status: "ok",
					apiKey: maskApiKey( provider.apiKey )
				};
			}
			catch ( error )
			{
				return {
					name: provider.name,
					status: "error",
					reason: error.message.substring( 0, 100 ),
					apiKey: maskApiKey( provider.apiKey )
				};
			}
		});

		const results = await Promise.allSettled( promises );

		const processedResults = results.map( ( r ) =>
		{
			if ( r.status === "fulfilled" )
			{
				return r.value;
			}
			return {
				name: "unknown",
				status: "error",
				reason: r.reason.message.substring( 0, 100 ),
				apiKey: "N/A"
			};
		});

		return processedResults.sort( ( a, b ) =>
		{
			if ( a.status === "ok" && b.status !== "ok" ) return -1;
			if ( a.status !== "ok" && b.status === "ok" ) return 1;
			return 0;
		});
	}

	_initializeProviders ( providers )
	{
		const allProviders = [];

		for ( const p of providers )
		{
			if ( Array.isArray( p.apiKey ) )
			{
				p.apiKey.forEach( ( key, i ) =>
				{
					if ( key )
					{
						allProviders.push({
							...p,
							apiKey: key,
							name: `${p.name}_${i + 1}`
						});
					}
				});
			}
			else if ( p.apiKey )
			{
				allProviders.push( p );
			}
		}
		return allProviders;
	}
}

module.exports = AIRouter;
</file>

<file path="docs/quickstart.md">
# Quickstart

Install, configure, and test in 5 minutes.

## Install

```bash
git clone https://github.com/mlibre/Unified-AI-Router.git
cd Unified-AI-Router
npm install
```

## Configure

```bash
cp .env.example .env
# Edit .env and add OPENROUTER_API_KEY or other provider keys
```

Edit `provider.js` to set your providers.

## Run

```bash
npm start
```

Server starts on `http://localhost:3000` with these endpoints:

- `POST /v1/responses` - OpenAI Responses API
- `POST /v1/chat/completions` - Chat Completions API
- `GET /v1/models` - List models
- `GET /health` - Health check

## Test

**Chat Completions:**

```bash
curl -X POST http://localhost:3000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"messages": [{"role":"user","content":"Hello"}], "model":"no_need"}'
```

**Responses API:**

```bash
curl -X POST http://localhost:3000/v1/responses \
  -H "Content-Type: application/json" \
  -d '{"input": "Hello", "model":"no_need"}'
```

**Streaming:**

```bash
curl -X POST http://localhost:3000/v1/responses \
  -H "Content-Type: application/json" \
  -d '{"input": "Say hello in 3 words", "model":"any-model", "stream": true}'
```

## Next

- Configure more providers in [`provider.js`](/configuration#providers)
- Check provider status: `GET /providers/status`
- See [Testing Guide](/testing) for comprehensive testing
- Check out [SDK Usage](/sdk-usage) for library integration
</file>

<file path="docs/providers.md">
# 🌍 Supported Providers

Configure multiple AI providers for automatic fallback and load balancing.

## 📋 Available Providers

The current deployment includes:

| Provider   | API Base URL                   | Model Examples                 | API Key Link                                     |
| ---------- | ------------------------------ | ------------------------------ | ------------------------------------------------ |
| OpenRouter | `https://openrouter.ai/api/v1` | `mistralai/devstral-2512:free` | [openrouter.ai/keys](https://openrouter.ai/keys) |

**Additional providers can be enabled by uncommenting and configuring them in `provider.js`:**

| Provider                     | API Base URL                                               | Model Examples                     | API Key Link                                                             |
| ---------------------------- | ---------------------------------------------------------- | ---------------------------------- | ------------------------------------------------------------------------ |
| OpenAI                       | `https://api.openai.com/v1`                                | `gpt-4`                            | [platform.openai.com/api-keys](https://platform.openai.com/api-keys)     |
| Groq                         | `https://api.groq.com/openai/v1`                           | `llama-3.1-70b-versatile`          | [console.groq.com](https://console.groq.com)                             |
| Google Gemini                | `https://generativelanguage.googleapis.com/v1beta/openai/` | `gemini-2.5-pro`                   | [aistudio.google.com/app/apikey](https://aistudio.google.com/app/apikey) |
| Cohere                       | `https://api.cohere.ai/v1`                                 | `command-r-plus`                   | [dashboard.cohere.com/api-keys](https://dashboard.cohere.com/api-keys)   |
| Cerebras                     | `https://api.cerebras.ai/v1`                               | `llama3.1-70b`                     | [cloud.cerebras.ai](https://cloud.cerebras.ai)                           |
| Any OpenAI-Compatible Server | `http://server-url/`                                       | Any model supported by your server | Custom                                                                   |

## ⚙️ Configuration Examples

### OpenAI

```javascript
{
  name: "openai",
  apiKey: process.env.OPENAI_API_KEY,
  model: "gpt-4",
  apiUrl: "https://api.openai.com/v1"
}
```

### OpenRouter

```javascript
{
  name: "openrouter",
  apiKey: process.env.OPENROUTER_API_KEY,
  model: "mistralai/devstral-2512:free",
  apiUrl: "https://openrouter.ai/api/v1"
}
```

### Google Gemini

```javascript
{
  name: "gemini",
  apiKey: process.env.GEMINI_API_KEY,
  model: "gemini-2.5-pro",
  apiUrl: "https://generativelanguage.googleapis.com/v1beta/openai/"
}
```

### Groq

```javascript
{
  name: "groq",
  apiKey: process.env.GROQ_API_KEY,
  model: "llama-3.1-70b-versatile",
  apiUrl: "https://api.groq.com/openai/v1"
}
```

### Cohere

```javascript
{
  name: "cohere",
  apiKey: process.env.COHERE_API_KEY,
  model: "command-r-plus",
  apiUrl: "https://api.cohere.ai/v1"
}
```

### Cerebras

```javascript
{
  name: "cerebras",
  apiKey: process.env.CEREBRAS_API_KEY,
  model: "llama3.1-70b",
  apiUrl: "https://api.cerebras.ai/v1"
}
```

### Custom OpenAI-Compatible Server

```javascript
{
  name: "custom-server",
  apiKey: process.env.SERVER_API_KEY, // Optional: depends on server
  model: "your-model-name",
  apiUrl: "http://localhost:4000/v1"
}
```

## 🎯 Provider Priority and Failover

Providers are tried in order until one succeeds. When a provider fails (due to network errors, API limits, or circuit breaker activation), it is automatically moved to the end of the provider list. This ensures that unhealthy providers stay down and healthy providers are tried first in subsequent requests.

```javascript
module.exports = [
  // Try this first
  {
    name: "openrouter",
    apiKey: process.env.OPENROUTER_API_KEY,
    model: "mistralai/devstral-2512:free",
    apiUrl: "https://openrouter.ai/api/v1"
  },
  // Fallback if first fails
  {
    name: "openai",
    apiKey: process.env.OPENAI_API_KEY,
    model: "gpt-3.5-turbo",
    apiUrl: "https://api.openai.com/v1"
  },
  // Last resort
  {
    name: "gemini",
    apiKey: process.env.GEMINI_API_KEY,
    model: "gemini-1.5-flash",
    apiUrl: "https://generativelanguage.googleapis.com/v1beta/openai/"
  }
];
```

### Automatic Failover Behavior

1. **First Request**: Providers are tried in the order defined above
2. **On Failure**: If `openrouter` fails, it's moved to the end of the list
3. **Next Request**: The order becomes `openai`, `gemini`, `openrouter`
4. **Continuous Adaptation**: Failed providers remain at the end until they succeed again

This mechanism works alongside circuit breakers to provide robust fallback behavior.

## 🔀 Load Balancing

Use multiple API keys for the same provider:

```javascript
{
  name: "openai",
  apiKey: [
    process.env.OPENAI_API_KEY_1,
    process.env.OPENAI_API_KEY_2,
    process.env.OPENAI_API_KEY_3
  ],
  model: "gpt-4",
  apiUrl: "https://api.openai.com/v1"
}
```

## 🛡️ Circuit Breaker Settings

Configure reliability settings per provider. Default settings:

- **timeout**: 300000ms (5 minutes)
- **errorThresholdPercentage**: 50%
- **resetTimeout**: 9000000ms (15 minutes)

Override defaults per provider:

```javascript
{
  name: "openai",
  apiKey: process.env.OPENAI_API_KEY,
  model: "gpt-4",
  apiUrl: "https://api.openai.com/v1",
  circuitOptions: {
    timeout: 30000,              // 30 second timeout (override default)
    errorThresholdPercentage: 50, // Open after 50% failures (matches default)
    resetTimeout: 300000         // Try again after 5 minutes (override default)
  }
}
```

## 📊 Provider Status

Check provider health:

```bash
curl http://localhost:3000/providers/status
```

Response includes:

- Provider name and status
- Circuit breaker state
- Recent error counts
- Response times
</file>

<file path="AGENTS.md">
# Core Rules

The following principles and rules **MUST** always be followed, under all circumstances:

## I. Lightweight Architecture

Code, logic, and architecture **MUST** remain lightweight. Dependencies **MUST** be minimal and purposeful.

## II. Simple and Minimalist Implementation

Code **MUST** be simple, clear, and readable—prefer straightforward, maintainable solutions over complex ones.  
Keep the codebase minimal: avoid clever or tricky one-liners in favor of clarity.  
Keep code and documentation clean: avoid duplication.

## III. Developer-Centric Documentation

All documentation **MUST** be developer-focused, with clear, concise technical explanations. Quickstart guides **MUST** enable local setup in under 5 minutes.

## IV. Change Management

When changes are made, update the version in `package.json` and revise documentation (Markdown files) to reflect them.

## V. Comprehensive Change Analysis

When implementing or fixing code, always verify correctness by analyzing related files and dependencies. But never write or run tests.

## VI. Docs-Code Consistency

Documentation and code **MUST** stay in sync:

- Update docs whenever code changes and vice versa if docs are updated.
- Docs must match real behaviors.
- Any mismatch between docs and code should be addressed.
</file>

<file path="package.json">
{
  "name": "unified-ai-router",
  "version": "3.9.2",
  "description": "A unified interface and openai-compatible server for multiple LLM providers with automatic fallback. Supports providers like Openrouter, Grok, and more, ensuring reliability and flexibility for your AI applications.",
  "license": "ISC",
  "author": "mlibre",
  "type": "commonjs",
  "homepage": "https://mlibre.github.io/Unified-AI-Router/",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/mlibre/Unified-AI-Router.git"
  },
  "bugs": {
    "url": "https://github.com/mlibre/Unified-AI-Router/issues"
  },
  "main": "main.js",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1",
    "start": "node openai-server.js",
    "repomix": "repomix . --ignore '.gitignore,**/favicons/,./tests,docs/public,docs/.vitepress/cache,docs/.vitepress/dist,/node_modules/,/.git/,**/*.png,/.ttf,**/.woff2,dist/,build/,/package-lock.json,/yarn.lock,.github/'",
    "docs:dev": "vitepress dev docs",
    "docs:build": "vitepress build docs",
    "docs:preview": "vitepress preview docs"
  },
  "keywords": [
    "ai",
    "openai-compatible",
    "openai-compatible-server",
    "llm",
    "fallback",
    "load-balancing",
    "openai",
    "gemini",
    "chatbot",
    "router",
    "multi-provider",
    "artificial-intelligence",
    "grok",
    "openrouter",
    "cohere",
    "cerebras"
  ],
  "dependencies": {
    "axios": "^1.13.2",
    "cors": "^2.8.5",
    "dotenv": "^17.2.3",
    "eslint": "^9.39.2",
    "express": "^5.2.1",
    "openai": "^6.15.0",
    "opossum": "^9.0.0",
    "pino": "^10.1.0",
    "pino-pretty": "^13.1.3"
  },
  "devDependencies": {
    "vitepress": "^2.0.0-alpha.15"
  }
}
</file>

<file path="readme.md">
# 🚀 Unified AI Router

<div align="center">

![GitHub package.json version (branch)](https://img.shields.io/github/package-json/v/mlibre/Unified-AI-Router/main?label=Unified%20AI%20Router)  
**The OpenAI-Compatible API Server & SDK for Reliable AI Applications**  

*Production-ready Express server and Node.js library with multi-provider AI routing, automatic fallback, and circuit breakers*

</div>

* [🎯 Why Unified AI Router?](#-why-unified-ai-router)
* [⚡ Quick Start](#-quick-start)
  * [📦 1. Installation](#-1-installation)
  * [⚙️ 2. Quick Configuration](#️-2-quick-configuration)
  * [🚀 3. Start Using the Server](#-3-start-using-the-server)
  * [📚 4. SDK Usage](#-4-sdk-usage)
* [⚙️ Configuration](#️-configuration)
  * [🔧 Environment Configuration (`.env`)](#-environment-configuration-env)
  * [🏗️ Provider Configuration (`provider.js`)](#️-provider-configuration-providerjs)
* [🚀 OpenAI-Compatible Server](#-openai-compatible-server)
  * [🌐 Web Chatbot Interface](#-web-chatbot-interface)
  * [💬 Chat Request](#-chat-request)
  * [🛠️ Chat Tool Calling Request](#️-chat-tool-calling-request)
  * [🗣️ Responses API Request](#️-responses-api-request)
* [📚 SDK Examples](#-sdk-examples)
  * [💬 Simple Chat Completion](#-simple-chat-completion)
  * [🌊 Chat Completion Streaming](#-chat-completion-streaming)
  * [🛠️ Chat Completion Tool Calling](#️-chat-completion-tool-calling)
  * [🗣️ Simple Responses API](#️-simple-responses-api)
  * [🌊 Responses API Streaming](#-responses-api-streaming)
  * [🛠️ Responses API Tool Calling](#️-responses-api-tool-calling)
  * [🔀 Multiple API Keys for Load Balancing](#-multiple-api-keys-for-load-balancing)
* [📋 Supported Providers](#-supported-providers)
* [🏗️ Architecture Overview](#️-architecture-overview)
* [🚀 Deployment](#-deployment)
  * [🏗️ Render.com Deployment](#️-rendercom-deployment)
* [📊 Comparison with Direct OpenAI API](#-comparison-with-direct-openai-api)
  * [🎯 Using Direct OpenAI API](#-using-direct-openai-api)
  * [🔗 Using Unified AI Router](#-using-unified-ai-router)
* [🏗️ Project Structure](#️-project-structure)
* [🧪 Testing](#-testing)
  * [🧪 Running the Test Suite](#-running-the-test-suite)
* [📄 License](#-license)
* [🔗 Links](#-links)

---

## 🎯 Why Unified AI Router?

Building reliable AI applications shouldn't require choosing between providers or managing complex fallback logic. **Unified AI Router** eliminates the complexity of multi-provider AI integration by providing:

* **🔄 Automatic Failover**: If one provider fails, seamlessly switches to the next
* **🛡️ Circuit Breaker Protection**: Prevents cascading failures across your infrastructure
* **⚡ OpenAI Compatibility**: Drop-in replacement for any OpenAI-compatible client
* **🌐 Multi-Provider Support**: Works with 10+ AI providers and any OpenAI-compatible server
* **🚀 Production Server**: Ready-to-deploy OpenAI-compatible API server with built-in reliability
* **📚 Library Component**: Core AIRouter library for direct integration in your applications

---

## ⚡ Quick Start

Get your first AI response in under 5 minutes:

### 📦 1. Installation

```bash
git clone https://github.com/mlibre/Unified-AI-Router.git
cd Unified-AI-Router
npm install

# Or Using npm (for SDK usage)
npm install unified-ai-router
```

### ⚙️ 2. Quick Configuration

```bash
# Copy environment template
cp .env.example .env

# Edit .env and add at least one API key:
# OPENROUTER_API_KEY=...

# edit provider.js
# The server uses provider.js to define which providers to try and in what order
```

### 🚀 3. Start Using the Server

```bash
npm start

# Test it works
curl -X POST http://localhost:3000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [{"role": "user", "content": "Hello!"}],
    "model": "no_need" # Model will be managed by provider.js
  }'
```

### 📚 4. SDK Usage

```javascript
const AIRouter = require("unified-ai-router");

const providers = [
    {
    name: "openrouter", 
    apiKey: process.env.OPENROUTER_API_KEY,
    model: "mistralai/devstral-2512:free",
    apiUrl: "https://openrouter.ai/api/v1"
  },
  {
    name: "openai",
    apiKey: process.env.OPENAI_API_KEY,
    model: "gpt-4",
    apiUrl: "https://api.openai.com/v1"
  }
];

const llm = new AIRouter(providers);

// Your first AI request!
const response = await llm.chatCompletion([
  { role: "user", content: "Hello! Say something helpful about AI." }
]);

console.log(response.content);
```

---

## ⚙️ Configuration

Before running the server, you must configure both your environment variables and provider settings.

### 🔧 Environment Configuration (`.env`)

Copy the environment template and add your API keys:

```bash
# Copy environment template
cp .env.example .env

# Edit .env and add your API keys:
# OPENAI_API_KEY=sk-your-openai-key-here
# OPENROUTER_API_KEY=your-openrouter-key-here
# PORT=3000 # Optional: server port (default: 3000)
```

### 🏗️ Provider Configuration (`provider.js`)

The `provider.js` file defines which AI providers to use and in what order. The server will try providers sequentially until one succeeds.

<details>
<summary><strong>Click to view provider configuration examples</strong></summary>

**Basic provider configuration:**

```javascript
module.exports = [
  {
    name: "openrouter",
    apiKey: process.env.OPENROUTER_API_KEY,
    model: "mistralai/devstral-2512:free",
    apiUrl: "https://openrouter.ai/api/v1"
  },
  {
    name: "openai",
    apiKey: process.env.OPENAI_API_KEY,
    model: "model",
    apiUrl: "https://api.openai.com/v1",
    circuitOptions: {
      timeout: 30000,           // 30 second timeout
      errorThresholdPercentage: 50, // Open after 50% failures
      resetTimeout: 300000      // Try again after 5 minutes
    }
  },
  {
    name: "openai-compatible-server",
    apiKey: [process.env.SERVER_API_KEY_1, process.env.SERVER_API_KEY_2],
    model: "name",
    apiUrl: "http://localhost:4000/v1" 
  }
  // Add more providers...
];
```

**Configuration options:**

* `name`: Provider identifier for logging and fallback
* `apiKey`: API key from environment variables
* `model`: Default model for this provider
* `apiUrl`: Provider's API base URL
* `circuitOptions`: Advanced reliability settings (optional)

**Provider priority**: Providers are tried in order - if the first fails, it automatically tries the next.

</details>

---

## 🚀 OpenAI-Compatible Server

The server provides a OpenAI-compatible API with all the reliability features built-in.

After configuring `.env` and `provider.js` (as explained in the Configuration section), start the server:

```bash
npm start
```

The server provides these endpoints at `http://localhost:3000`:

| Endpoint                    | Description                                  |
| --------------------------- | -------------------------------------------- |
| `GET /`                     | Web chatbot interface                        |
| `POST /v1/responses`        | Responses API                                |
| `POST /responses`           | Alternative responses API path               |
| `POST /v1/chat/completions` | Chat completions (streaming & non-streaming) |
| `POST /chat/completions`    | Alternative chat completions path            |
| `GET /v1/models`            | List available models                        |
| `GET /health`               | Health check endpoint                        |
| `GET /providers/status`     | Provider status and health                   |

### 🌐 Web Chatbot Interface

The server includes a responsive web chatbot interface accessible at: `http://localhost:3000/`

Features include mobile responsiveness, dark/light themes, conversation history, settings panel, and auto-fallback using the same reliability system as the API.

### 💬 Chat Request

<details>
<summary><strong>Click to view simple chat example</strong></summary>

**Request:**

```bash
curl -X POST http://localhost:3000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "any-model",
    "messages": [
      {
        "role": "system",
        "content": "You are a helpful assistant."
      },
      {
        "role": "user",
        "content": "hey"
      }
    ],
    "temperature": 0.7,
    "stream": false
  }'
```

**Response:**

```json
{
  "id": "gen-1767375039-pUm7PBSoyXFJtS6AVAup",
  "provider": "Xiaomi",
  "model": "xiaomi/mimo-v2-flash:free",
  "object": "chat.completion",
  "created": 1767375039,
  "choices": [
    {
      "logprobs": null,
      "finish_reason": "stop",
      "native_finish_reason": "stop",
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "Hello! How can I help you today?",
        "refusal": null,
        "reasoning": null
      }
    }
  ],
  "usage": {
    "prompt_tokens": 20,
    "completion_tokens": 10,
    "total_tokens": 30,
    "cost": 0,
    "is_byok": false,
    "prompt_tokens_details": {
      "cached_tokens": 0,
      "audio_tokens": 0,
      "video_tokens": 0
    },
    "cost_details": {
      "upstream_inference_cost": null,
      "upstream_inference_prompt_cost": 0,
      "upstream_inference_completions_cost": 0
    },
    "completion_tokens_details": {
      "reasoning_tokens": 0,
      "image_tokens": 0
    }
  }
}
```

</details>

### 🛠️ Chat Tool Calling Request

<details>
<summary><strong>Click to view tool calling example</strong></summary>

The server supports function calling with streaming responses:

```bash
curl -X POST http://localhost:3000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "no_need_to_mention",
    "messages": [
      {
        "role": "system",
        "content": "You are a helpful assistant."
      },
      {
        "role": "user",
        "content": "how is the weather in mashhad, tehran. use tools"
      }
    ],
    "tools": [
      {
        "type": "function",
        "function": {
          "name": "get_weather",
          "description": "Get the current weather forecast for a given city.",
          "parameters": {
            "type": "object",
            "properties": {
              "city": {
                "type": "string",
                "description": "The name of the city (e.g., Tehran) to get the weather for."
              }
            },
            "required": ["city"],
            "additionalProperties": false
          },
          "strict": true
        }
      }
    ],
    "temperature": 0.7,
    "stream": true
  }'
```

**Expected Response:**

```json
{
  "id": "gen-1767373622-GrCl6IaMadukHESGLXrg",
  "provider": "Xiaomi",
  "model": "xiaomi/mimo-v2-flash:free",
  "object": "chat.completion",
  "created": 1767373622,
  "choices": [
    {
      "logprobs": null,
      "finish_reason": "tool_calls",
      "native_finish_reason": "tool_calls",
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "I'll check the weather for both Mashhad and Tehran for you.",
        "refusal": null,
        "reasoning": null,
        "tool_calls": [
          {
            "type": "function",
            "index": 0,
            "id": "call_b7e5a323a134468c8b068401",
            "function": {
              "name": "get_weather",
              "arguments": "{\"city\": \"Mashhad\"}"
            }
          },
          {
            "type": "function",
            "index": 1,
            "id": "call_d26d59f9fdec4ef0b33cfc1e",
            "function": {
              "name": "get_weather",
              "arguments": "{\"city\": \"Tehran\"}"
            }
          }
        ]
      }
    }
  ],
  "usage": {
    "prompt_tokens": 410,
    "completion_tokens": 57,
    "total_tokens": 467,
    "cost": 0,
    "is_byok": false,
    "prompt_tokens_details": {
      "cached_tokens": 0,
      "audio_tokens": 0,
      "video_tokens": 0
    },
    "cost_details": {
      "upstream_inference_cost": null,
      "upstream_inference_prompt_cost": 0,
      "upstream_inference_completions_cost": 0
    },
    "completion_tokens_details": {
      "reasoning_tokens": 0,
      "image_tokens": 0
    }
  }
}
```

</details>

### 🗣️ Responses API Request

<details>
<summary><strong>Click to view responses API example</strong></summary>

The server also supports OpenAI's Responses API with the same reliability features:

**Non-Streaming Response:**

```bash
curl -X POST http://localhost:3000/v1/responses \
  -H "Content-Type: application/json" \
  -d '{
    "model": "no_need_to_mention",
    "input": "Tell me a short story about AI.",
    "temperature": 0.7,
    "stream": false
  }'
```

**Expected Response:**

```json
{
  "object": "response",
  "id": "gen-1767387778-jshLoROQPnUYsIWuUEZ0",
  "created_at": 1767387778,
  "model": "xiaomi/mimo-v2-flash:free",
  "error": null,
  "output_text": "Once upon a time, there was an AI that learned to dream...",
  "output": [
    {
      "role": "assistant",
      "type": "message",
      "status": "completed",
      "content": [
        {
          "type": "output_text",
          "text": "Once upon a time, there was an AI that learned to dream...",
          "annotations": []
        }
      ],
      "id": "msg_tmp_q5d6cj4d5nq"
    }
  ],
  "usage": {
    "input_tokens": 48,
    "input_tokens_details": {
      "cached_tokens": 0
    },
    "output_tokens": 100,
    "output_tokens_details": {
      "reasoning_tokens": 0
    },
    "total_tokens": 148,
    "cost": 0
  }
}
```

**Streaming Response:**

```bash
curl -X POST http://localhost:3000/v1/responses \
  -H "Content-Type: application/json" \
  -d '{
    "model": "no_need_to_mention",
    "input": "Say hello in exactly 3 words.",
    "stream": true
  }' \
  --no-buffer
```

**Expected Streaming Response:**

```json
data: {"type":"response.created","response":{...}}

data: {"type":"response.output_text.delta","delta":"Hi"}

data: {"type":"response.output_text.delta","delta":" there,"}

data: {"type":"response.output_text.delta","delta":" friend"}

data: {"type":"response.completed","response":{...}}

data: [DONE]
```

</details>

---

## 📚 SDK Examples

### 💬 Simple Chat Completion

<details>
<summary><strong>Click to view example</strong></summary>

```javascript
const AIRouter = require("unified-ai-router");
require("dotenv").config();

const providers = [
  {
    name: "openai",
    apiKey: process.env.OPENAI_API_KEY,
    model: "gpt-4",
    apiUrl: "https://api.openai.com/v1"
  }
];

const llm = new AIRouter(providers);

const messages = [
  { role: "system", content: "You are a helpful coding assistant." },
  { role: "user", content: "Write a function to reverse a string in JavaScript." }
];

const response = await llm.chatCompletion(messages, {
  temperature: 0.7,
  max_tokens: 500
});

console.log(response.content);
```

</details>

### 🌊 Chat Completion Streaming

<details>
<summary><strong>Click to view example</strong></summary>

```javascript
const stream = await llm.chatCompletion(messages, {
  temperature: 0.7,
  stream: true  // Enable streaming
});

for await (const chunk of stream) {
  if (chunk.content) {
    process.stdout.write(chunk.content);
  }
}
```

</details>

### 🛠️ Chat Completion Tool Calling

<details>
<summary><strong>Click to view example</strong></summary>

```javascript
const tools = [
  {
    type: "function",
    function: {
      name: "get_weather",
      description: "Get current weather for a location",
      parameters: {
        type: "object",
        properties: {
          location: { type: "string", description: "City name" }
        }
      }
    }
  }
];

const response = await llm.chatCompletion(messages, {
  tools: tools,
  tool_choice: "auto"
});

console.log(response.tool_calls);
```

</details>

### 🗣️ Simple Responses API

<details>
<summary><strong>Click to view example</strong></summary>

```javascript
// Basic Responses API usage
const response = await llm.responses(
  "Tell me about artificial intelligence.",
  {
    temperature: 0.7,
    max_tokens: 500
  }
);

console.log(response.output_text);
```

</details>

### 🌊 Responses API Streaming

<details>
<summary><strong>Click to view example</strong></summary>

```javascript
const stream = await llm.responses(
  "Write a poem about coding.",
  {
    stream: true  // Enable streaming
  }
);

for await (const chunk of stream) {
  if (chunk.type === 'response.output_text.delta') {
    process.stdout.write(chunk.delta);
  }
}
```

</details>

### 🛠️ Responses API Tool Calling

<details>
<summary><strong>Click to view example</strong></summary>

```javascript
const tools = [
  {
    type: "function",
    name: "multiply",
    description: "Multiply two numbers",
    parameters: {
      type: "object",
      properties: {
        a: { type: "number", description: "First number" },
        b: { type: "number", description: "Second number" }
      },
      required: ["a", "b"],
      additionalProperties: false
    }
  },
  {
    type: "function",
    name: "get_weather",
    description: "Get the current weather forecast for a given city.",
    parameters: {
      type: "object",
      properties: {
        city: { type: "string", description: "The name of the city to get the weather for." }
      },
      required: ["city"],
      additionalProperties: false
    }
  }
];

const response = await llm.responses(
  "How is the weather in Mashhad and Tehran? Use tools.",
  {
    tools: tools,
    temperature: 0.7
  }
);

console.log(response.output_text);
console.log(response.tool_calls);
```

</details>

### 🔀 Multiple API Keys for Load Balancing

<details>
<summary><strong>Click to view example</strong></summary>

```javascript
const providers = [
  {
    name: "openai",
    apiKey: [  // Array of API keys
      process.env.OPENAI_API_KEY_1,
      process.env.OPENAI_API_KEY_2,
      process.env.OPENAI_API_KEY_3
    ],
    model: "gpt-4",
    apiUrl: "https://api.openai.com/v1"
  }
];
```

</details>

## 📋 Supported Providers

| Provider                     | API Base URL                                               | Model Examples                     |
| ---------------------------- | ---------------------------------------------------------- | ---------------------------------- |
| OpenRouter                   | `https://openrouter.ai/api/v1`                             | `mistralai/devstral-2512:free`     |
| OpenAI                       | `https://api.openai.com/v1`                                | `gpt-4`                            |
| Groq                         | `https://api.groq.com/openai/v1`                           | `llama-3.1-70b-versatile`          |
| Google Gemini                | `https://generativelanguage.googleapis.com/v1beta/openai/` | `gemini-2.5-pro`                   |
| Cohere                       | `https://api.cohere.ai/v1`                                 | `command-r-plus`                   |
| Any OpenAI-Compatible Server | `http://server-url/`                                       | Any model supported by your server |
| Cerebras                     | `https://api.cerebras.ai/v1`                               | `llama3.1-70b`                     |

**Get API Keys:**

* **OpenAI**: [platform.openai.com/api-keys](https://platform.openai.com/api-keys)
* **OpenRouter**: [openrouter.ai/keys](https://openrouter.ai/keys)
* **Grok**: [console.x.ai](https://console.x.ai/)
* **Google Gemini**: [aistudio.google.com/app/apikey](https://aistudio.google.com/app/apikey)
* **Cohere**: [dashboard.cohere.com/api-keys](https://dashboard.cohere.com/api-keys)
* **Cerebras**: [cloud.cerebras.ai](https://cloud.cerebras.ai)
* **Any OpenAI-Compatible Server**: LiteLLM, custom proxies, or any OpenAI-compatible endpoint

---

## 🏗️ Architecture Overview

Unified AI Router follows a **fail-fast, quick-recovery** architecture:

```text
┌───────────────┐     ┌─────────────────┐     ┌───────────────┐
│   Your App    │───▶│      OpenAI     │───▶│    AIRouter   │
│  (Any Client) │     │      Server     │     |     (SDK)     │
└───────────────┘     └─────────────────┘     └───────────────┘
                                                      │
                                                      ▼
                                            ┌──────────────────────┐
                                            │    Provider Loop     │
                                            │  (Try each provider) │
                                            └──────────────────────┘
                                                      │
                            ┌─────────────────────────┼─────────────────────────┐
                            │                         │                         │
                            ▼                         ▼                         ▼
                    ┌───────────────┐        ┌───────────────┐        ┌───────────────┐
                    │  Provider 1   │        │  Provider 2   │        │  Provider N   │
                    │ ┌───────────┐ │        │ ┌───────────┐ │        │ ┌───────────┐ │
                    │ │  Circuit  │ │        │ │  Circuit  │ │        │ │  Circuit  │ │
                    │ │  Breaker  │ │        │ │  Breaker  │ │        │ │  Breaker  │ │
                    │ └───────────┘ │        │ └───────────┘ │        │ └───────────┘ │
                    │      │        │        │      │        │        │      │        │
                    │      ▼        │        │      ▼        │        │      ▼        │
                    │   AI Model    │        │   AI Model    │        │   AI Model    │
                    │  (Try First)  │        │  (Fallback)   │        │ (Last Resort) │
                    └───────────────┘        └───────────────┘        └───────────────┘
```

---

## 🚀 Deployment

### 🏗️ Render.com Deployment

1. **Dashboard Method:**

   ```bash
   # Push to GitHub first
   git push origin main
   
   # Then on Render.com:
   # 1. Create Web Service
   # 2. Connect repository
   # 3. Set Build Command: npm install
   # 4. Set Start Command: npm start
   # 5. Add environment variables (API keys)
   # 6. Deploy
   ```

2. **Verify Deployment:**

   ```bash
   curl https://your-app.onrender.com/health
   curl https://your-app.onrender.com/models
   ```

## 📊 Comparison with Direct OpenAI API

<details>
<summary><strong>Click to view comparison examples</strong></summary>

### 🎯 Using Direct OpenAI API

```javascript
const OpenAI = require("openai");
const client = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

const response = await client.chat.completions.create({
  model: "gpt-4",
  messages: [{ role: "user", content: "Hello" }]
});

// ❌ No fallback - fails if OpenAI is down
// ❌ No circuit breaker - failures cascade
// ❌ No multi-provider support
```

### 🔗 Using Unified AI Router

```javascript
const AIRouter = require("unified-ai-router");

const providers = [
  { name: "openai", apiKey: process.env.OPENAI_API_KEY, model: "gpt-4" },
  { name: "backup", apiKey: process.env.BACKUP_KEY, model: "claude-3" }
];

const llm = new AIRouter(providers);
const response = await llm.chatCompletion([{ role: "user", content: "Hello" }]);

// ✅ Automatic fallback if OpenAI fails
// ✅ Circuit breaker protection
// ✅ Multi-provider load balancing
// ✅ Same API interface as OpenAI
// ✅ Production-ready reliability
```

</details>

---

## 🏗️ Project Structure

```bash
Unified-AI-Router/
├── openai-server.js     # OpenAI-compatible server
├── main.js              # Core AIRouter library
├── provider.js          # Provider configurations
├── package.json         # Dependencies and scripts
├── .env.example         # Environment template
├── tests/               # Test suite
│   ├── chat/            # Chat completions tests
│   │   ├── chat.js                  # Basic chat functionality
│   │   ├── server-non-stream.js     # Server non-streaming tests
│   │   ├── server-stream.js         # Server streaming tests
│   │   └── tool-calling.js          # Chat tool calling tests
│   └── responses/       # Responses API tests
│       ├── server-responses.js             # Basic responses API
│       ├── conversation-tool-calling.js    # Conversation tool calling
│       ├── server-conversation-basic.js    # Multi-turn conversation
│       └── server-tool-calling.js          # Responses API tool calling
└── docs/                # VitePress documentation
    ├── index.md
    ├── quickstart.md
    └── configuration.md
```

---

## 🧪 Testing

The project includes comprehensive tests covering:

* **Library Functionality**: Core AIRouter class testing
* **Server Endpoints**: OpenAI-compatible API testing
* **Streaming Support**: Real-time response handling
* **Tool Calling**: Function calling capabilities
* **Error Handling**: Failure scenarios and fallbacks

### 🧪 Running the Test Suite

```bash
# Install dependencies
npm install

# Run individual tests

# Chat Completions Tests
node tests/chat/chat.js                # Basic chat functionality
node tests/chat/server-non-stream.js   # Server non-streaming
node tests/chat/server-stream.js       # Server streaming
node tests/chat/tool-calling.js        # Chat tool calling

# Responses API Tests
node tests/responses/server-responses.js           # Basic responses API
node tests/responses/conversation-tool-calling.js  # Conversation tool calling
node tests/responses/server-conversation-basic.js  # Multi-turn conversation
node tests/responses/server-tool-calling.js        # Responses API tool calling

```

---

## 📄 License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## 🔗 Links

* **Documentation**: [https://mlibre.github.io/Unified-AI-Router/](https://mlibre.github.io/Unified-AI-Router/)
* **Repository**: [https://github.com/mlibre/Unified-AI-Router](https://github.com/mlibre/Unified-AI-Router)
* **Issues**: [https://github.com/mlibre/Unified-AI-Router/issues](https://github.com/mlibre/Unified-AI-Router/issues)
* **NPM Package**: [https://www.npmjs.com/package/unified-ai-router](https://www.npmjs.com/package/unified-ai-router)

---

<div align="center">

**[⬆ Back to Top](#-unified-ai-router)**

Made with ❤️ by [mlibre](https://github.com/mlibre)

</div>
</file>

</files>
